{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('fivethirtyeight') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression coefficient confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start by creating a set of x-values (or “input variables”, “predictors”, “features”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata =...\n",
    "x=..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That just gave us ndata x-values ranging from -10 to 10, equally spaced.\n",
    "\n",
    "Now let’s create the beginnings of a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add everything together to make the ouput (y) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the TRUE model we’ll work with. Later we’ll refer to estimates of the b0 and b1 coefficients with b0hat and b1hat. Note that we’ve added noise to the model, normal with mean zero and standard deviation 500 (the rnorm command)\n",
    "\n",
    "Let’s look at a scatter plot of the x-y relationship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That’s a line with intercept b0, slope b1, and a bunch of noise added in.\n",
    "\n",
    "Now let’s assume we know b0 but want to figure out b1. A simple thing to do is “enumerate” values of b1 and see how they do on the residual sum of squares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1seq = ...\n",
    "\n",
    "one = ...  # this is going to be useful in making a matrix of estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're about to make a matrix of residuals for each candidate b1 value.  \n",
    "\n",
    "First, we'll make y_tile, a matrix where each column is the same replication of the original y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tile = np.tile(y,(len(b1seq),1)).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll make y_est, a matrix where each column is the estimated y values for each candidate b1.  \n",
    "\n",
    "To do this we'll use the outer product, which creates a matrix with products for each possible combination of elements.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_est = (b0+np.outer(x,b1seq))  # the \"outer\" product is the opposite of the \"inner\" product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I just added b0 directly because I’m assuming it’s known.\n",
    "\n",
    "\n",
    "Now we’re going to make a matrix of residuals squared. Rows correspond to each enumerated b1 value, and columns correspond to residuals for each individual estimate of y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResidSquareMatrix = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s get a vector of residual *sums* of squares. Each entry in the vector is an RSS for each estimate of b1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSS = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot RSS vs b1 we’ll see how well each enumarated value of b1 performs wrt RSS.  \n",
    "\n",
    "What do you think the plot will look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(b1seq, RSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us that the RSS is minimized at nearly 100. That’s what we’d hope for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of coefficient estimates\n",
    "Now we're going to estimate coefficients from a subset of the entire data set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to fit a linear model to the data.  Before we can we need to load scikit-learn, the library that gives us machine learning tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the idea by first grabbing one sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_n = 2000\n",
    "np.random.seed(1) # setting the random seed makes notebook runs repeatable.  \n",
    "\n",
    "# the next line gives n uniformly distributed numbers between 0 and ndata\n",
    "indx = np.random.randint(low = 0, high = ndata, size = sample_n)  \n",
    "\n",
    "xsample = ... # the linear model from scikit learn needs this form\n",
    "ysample = ... # the linear model from scikit learn needs this form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we build models with scikit learn is to first define an object that has the general model characteristics we desire.  Here what we want is a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_lm = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to fit the model to data we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_fit = ...\n",
    "\n",
    "print('The intercept is',lm_fit.intercept_,'and the slope is', lm_fit.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives us one estimate of the coefficients from a single sample.  For the choice of random seed above, the coefficients are close to the \"true\" ones, but certainly not equal.\n",
    "\n",
    "Let's see what that distribution of coefficients looks like if we repeatedly sample from the population of data x and y.\n",
    "\n",
    "First we initialize arrays to store data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_samples = 1000\n",
    "\n",
    "# the next lines initialize vectors to store all the values we're about to create.\n",
    "b0hat = np.zeros(number_samples)  \n",
    "b1hat = np.zeros(number_samples)  \n",
    "RSE = np.zeros(number_samples) \n",
    "SEb0 = np.zeros(number_samples) \n",
    "SEb1 = np.zeros(number_samples) \n",
    "CIb0 = np.zeros((number_samples,2))\n",
    "CIb1 = np.zeros((number_samples,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define functions for the RSE and standard errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidSE(x, y, n, lm):\n",
    "    return np.sqrt(np.sum((lm.predict(x) - y)**2)/(n-2))\n",
    "\n",
    "def StandErr_b0(RSE, n, x):\n",
    "    xbar = np.mean(x)\n",
    "    return np.sqrt(RSE**2*(1/n + xbar**2/np.sum((x - xbar)**2)))\n",
    "\n",
    "def StandErr_b1(RSE, n, x):\n",
    "    xbar = np.mean(x)\n",
    "    return np.sqrt(RSE**2*(1/np.sum((x - xbar)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run though a loop to estimate the model many times.  For each estimate we record the coefficients, standard errors, and 95% confidence intervals for the coefficients.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0,number_samples):\n",
    "    # next line gives n uniformly distributed numbers between 0 and ndata\n",
    "    ...  \n",
    "    \n",
    "    # get the samples:\n",
    "    ...\n",
    "    ...\n",
    "    \n",
    "    # fit the model and record coefficients\n",
    "    lm_fit = ...\n",
    "    b0hat[i] = ...\n",
    "    b1hat[i] = ...\n",
    "    \n",
    "    # compute the residual standard error (required for computing coefficient S.E.)\n",
    "    RSE[i] = ResidSE(...)\n",
    "    #np.sqrt(np.sum((lm_fit.predict(xsample) - ysample)**2)/(sample_n-2))\n",
    "    \n",
    "    # compute coefficient S.E.\n",
    "    SEb0[i] = StandErr_b0(...)\n",
    "    SEb1[i] = StandErr_b1(...)\n",
    "    \n",
    "    # compute 95% confidence intervals.\n",
    "    CIb0[i,:] = ...\n",
    "    CIb1[i,:] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the coefficients.  \n",
    "\n",
    "What is the largest and smallest likely value for each?  What do you think the average value of the distributions will be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.min(b0hat), np.mean(b0hat), np.max(b0hat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.min(b1hat), np.mean(b1hat), np.max(b1hat)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those average values are mighty close to the actual.  But the range is really big!  \n",
    "\n",
    "Let's look at the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "\n",
    "sns. ...\n",
    "\n",
    "plt.xlabel('estimated intercept')\n",
    "plt.title('b0hat KD estimate across 1000 samples')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "\n",
    "sns. ...\n",
    "\n",
    "plt.xlabel('estimated slope')\n",
    "plt.title('b1hat KD estimate across 1000 samples')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here is the challenge question.  How many times do you expect the true value will be outside the 95% confidence interval for each model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0_below = np.greater(CIb0[:,0], b0) # true if true value below C.I.\n",
    "b0_above = np.less(CIb0[:,1], b0) # true if true value above C.I.\n",
    "\n",
    "b0_out_of_CI = np.logical_or(b0_below, b0_above) # true if either is true (i.e. it's outside)\n",
    "\n",
    "print(...) # number of confidence intervals that don't contain original value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fraction of estimates outside the 95% CI is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_below = np.greater(CIb1[:,0], b1) # true if true value below C.I.\n",
    "b1_above = np.less(CIb1[:,1], b1) # true if true value above C.I.\n",
    "\n",
    "b1_out_of_CI = np.logical_or(b1_below, b1_above) # true if either is true (i.e. it's outside)\n",
    "\n",
    "sum(b1_out_of_CI)/number_samples # fraction of confidence intervals that don't contain original value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R$^2$\n",
    "First let's compute the Rsquared for the last sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
