\documentclass[aspectratio=169, handout]{beamer}
%\documentclass[aspectratio=169]{beamer}


\usefonttheme{professionalfonts}
\usetheme{boxes}
\mode<presentation>
%{
%  \usecolortheme{whale}%whale
%  % or ...
%  \setbeamercovered{transparent}
%  \definecolor{BerkeleyBlue}{RGB}{0,50,98}
%  \definecolor{UtahRed}{RGB}{204,0,0}
%  \definecolor{DarkGreen}{RGB}{0,128,0}
%%\setbeamercolor{title}{fg=BerkeleyBlue}
%%\setbeamercolor{frametitle}{fg=BerkeleyBlue}
%\setbeamercolor{structure}{fg=BerkeleyBlue}
%}

\usepackage{tikz}
\usetikzlibrary{tikzmark,fit,shapes.geometric}


\newcommand{\transp}{^{\rm{T}}}

\usepackage{cases}
\usepackage[english]{babel}
% or whatever
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage[latin1]{inputenc}
\usepackage[super]{nth}
% or whatever
%\setbeamertemplate{footline}[page number]
\setbeamertemplate{footline}
        {
      \leavevmode%
      \hbox{%
      \begin{beamercolorbox}[wd=.333333\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
        \usebeamerfont{author in head/foot}\insertshortauthor%~~(\insertshortinstitute)
      \end{beamercolorbox}%
      \begin{beamercolorbox}[wd=.333333\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
        \usebeamerfont{title in head/foot}\insertshorttitle
      \end{beamercolorbox}%
      \begin{beamercolorbox}[wd=.333333\paperwidth,ht=2.25ex,dp=1ex,right]{date in head/foot}%
        \usebeamerfont{date in head/foot}\insertshortdate{}\hspace*{2em} \insertframenumber{}  \hspace*{2em}%/ \inserttotalframenumber\hspace*{2ex} 

    %#turning the next line into a comment, erases the frame numbers
        

      \end{beamercolorbox}}%
      \vskip 0pt%
    }

\usepackage{times}
\usepackage[T1]{fontenc}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tabularx}
\usepackage{algpseudocode}
\usepackage{mathrsfs}
\usepackage{textpos}
\usepackage{graphicx}
\usepackage{tcolorbox}
\usepackage{multicol}
\usepackage{tikz}
\usetikzlibrary{arrows.meta,shapes.arrows}
%\setkeys{Gin}{draft}
\usepackage{caption}
\captionsetup{font=scriptsize,labelfont=scriptsize}
\usepackage{color}
\DeclareCaptionFont{blue}{\color{blue}}
\captionsetup{labelfont=blue}
\usepackage{tikz}
\tikzset{
  every overlay node/.style={
    draw=white,anchor=north west,
  },
}
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;}
\def\tikzoverlay{%
   \tikz[baseline,overlay]\node[every overlay node]
}%
%\DeclareGraphicsRule{.png}{png}{.png.bb}{}

\newtheorem{assumption}{Assumption} %jw

\newcommand{\T}{{\rm T}}

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}
\setcounter{tocdepth}{1}
\beamertemplatenavigationsymbolsempty


\title[Lecture 8] % (optional, use only with long paper titles)
{Data, Environment and Society: \\{Lecture 8: Introduction to Models}}


%\subtitle
%{Include Only If Paper Has a Subtitle}

\author[ER131: Data, Environment and Society] 
{Instructor: Duncan Callaway \newline
GSI: Salma Elmallah} 
% - Give the names in the same order as the appear in the paper.
% - Use the \inst{?} command only if the authors have different
%   affiliation.

%\logo{
%\includegraphics[width=1.5cm,height=1.5cm,keepaspectratio]{uvic_logo_h.jpg}
%}
\vspace{-20mm}
\institute[UC Berkeley] % (optional, but mostly needed)
 {\small{ \bf September 24, 2019}}


\date[September 24, 2019]


\begin{document}

\begin{frame}[plain, noframenumbering]
  \titlepage
\end{frame}

\begin{frame}{Announcements and agenda}

Reading
\begin{itemize}
	\item Today: DS100 Ch 10, ISLR Ch 2
	\item Thursday: ISLR Ch 3.1
	\item Next week: ISLR 3.2-3.3
\end{itemize}

\vspace{5mm}

\pause

Today:
\begin{itemize}
	\item Visualization finish-up -- types of plots
	\item What is a model, how do we estimate its parameters?
	\item Terminology going forward
	\item What's the bias-variance tradeoff
	\item Lighting review: estimating least squares regression coefficients
\end{itemize}
\end{frame}

\begin{frame}{What is a mathematical model?}

\pause
A system of equations that relates one set of variables to another set of variables.
\pause
\hspace{5mm}

Examples

\begin{enumerate}
\item The distance a cheetah travels in $h$ hours at 65 miles per hour.
\begin{align*}
d(h) = 65 h
\end{align*}
 

\item The height of a rock thrown in straight up, after $t$ seconds:
\begin{align*}
h(t) = \frac{1}{2}a t^2 + v_0t + h_0
\end{align*}
... with gravity acceleration $a$, at initial velocity $v_0$, from initial height $h_0$.

\item The mean surface temperature of the Earth in 2100:
\begin{align*}
T_{\text{surf}} = f(\text{a lot of different variables!})
\end{align*}
\end{enumerate}

\end{frame}


\begin{frame}{Models don't have to be ``first principles''}

\begin{enumerate}

\item Number of ER visits for cardiac problems per day

\begin{align*}
N_{ER} = \beta_0+ \beta_1\cdot PM25
\end{align*}

where $PM25$ is PM 2.5 concentrations.

\item HDI as a function of energy access:

\begin{align*}
HDI = \beta_0 + \beta_1 r + \beta_2 r^2
\end{align*}

where $r$ is the percentage of households in a country with access to electricity.
\end{enumerate}

\end{frame}



\begin{frame}{What is model \textit{estimation}?}

\pause

The process of choosing a model's parameters using a data set of measurements.  

\pause
\hspace{5mm}

For example:

\begin{enumerate}
\item Record the height of a rock, and the time you made the measurement, several times as it travels through the air.  Then use those data to choose the parameters of your ``first principles'' model so that its output matches your observations.

\hspace{5mm}

\item Obtain an administrative database of daily ER visits and the corresponding PM2.5 concentrations for each day.  Use those data to choose $\beta_0$ and $\beta_1$ in $
N_{ER} = \beta_0+\beta_1\cdot PM25$ so you can predict $N_{ER}$ well from PM2.5.  
\end{enumerate}

\end{frame}

\begin{frame}{Which is which?}

One is ER visits as a function of PM2.5 concentrations.  One is height of a rock as a function of time.

\vspace{5mm}

\includegraphics[scale=0.475]{data/Huang_et_al/huang_pm25vcirc_notitle.pdf}\vspace{10mm}\hspace{8mm}\includegraphics[scale=0.475]{data/Huang_et_al/projectile_notitle.pdf}

\end{frame}

\begin{frame}{Which is which?}


One is ER visits as a function of PM2.5 concentrations.  One is height of a rock as a function of time.

\includegraphics[scale=0.475]{data/Huang_et_al/huang_pm25vcirc_regplot.pdf}\includegraphics[scale=0.475]{data/Huang_et_al/projectile.pdf}

\begin{tiny}
Source for hospital data: Hwang, S. H. \textit{et al} (2017), PloS one, 12(8).
\end{tiny}

\end{frame}

\begin{frame}{How did you choose?}

\includegraphics[scale=0.475]{data/Huang_et_al/huang_pm25vcirc_regplot.pdf}\includegraphics[scale=0.475]{data/Huang_et_al/projectile.pdf}

\begin{tiny}
Source for hospital data: Hwang, S. H. \textit{et al} (2017), PloS one, 12(8).
\end{tiny}

\pause

\begin{itemize}
\item The right plot has much less scatter
\item The right plot seems to be describing a more systematic process
\end{itemize}


\end{frame}


\begin{frame}{Could the projectile plot ever look like this?  How?}

\begin{columns}

\column{0.5\textwidth}
\includegraphics[scale=0.5]{data/Huang_et_al/projectile_noise.pdf}

\column{0.5\textwidth}

\pause

\begin{itemize}
\item Where could this noise come from?
\begin{itemize}
\item Measurement error: the height numbers are erroneous
\item Model error: we didn't capture the whole process, for example a windy environment
\end{itemize}
\end{itemize}
\end{columns}

\end{frame}


\begin{frame}{Why might we build a model?}

\pause

Prediction.
\begin{itemize}
\item Where will the projectile be in 5 seconds?
\item I'm building a hospital in a city where I know the air quality trends as well as a bunch of other variables.  How big should the ER be?
\end{itemize}

\hspace{5mm}

Inference: Estimating a parameter
\begin{itemize}
\item What is the acceleration of gravity?
\item What is the correlation between air quality and ER visits?
\end{itemize}

\hspace{5mm}

\textit{Causal }Inference:
\begin{itemize}
\item Does PM2.5 cause heart attacks? 
\end{itemize} 

\end{frame}

\begin{frame}{Expectations for the model and data...}

Prediction:
\begin{itemize}
\item Low expectations! As long as the independent variables are correlated with the dependent variables, we can make predictions.
\end{itemize}
\hspace{2mm}

Inference: 
\begin{itemize}
\item Moderate expectations on the model: It needs to be sufficiently interpretable that we can understand what parameters mean
\end{itemize}
\hspace{2mm}

\textit{Causal }Inference:
\begin{itemize}
\item Very high expectations!  We need to be confident that \textit{only} the independent variable is changing systematically across measurements.  
\item Otherwise we can't rule out the possibility that some other unobserved variable is impacting our observations.
\end{itemize}

\end{frame}


\begin{frame}{You say regressor, I say feature}

\begin{table}[]
\begin{tabular}{lp{5.5cm}p{5.5cm}}
 \textbf{Math} & \textbf{Machine learning} & \textbf{Statistics}  \\
 \hline
 \hline
  $x$& \uncover<2->{\textbf{independent variable}, predictor, input variable, feature} & \uncover<2->{\textbf{independent variable}, regressor, covariate,  explanatory variable, right hand variable} \\
 $y$ &  \uncover<2->{\textbf{dependent variable}, output variable, response variable, target} & \uncover<2->{\textbf{dependent variable,} outcome variable, left-hand side variable.}
\end{tabular}
\end{table}

\uncover<3>{In this class, I'll stick to
\begin{enumerate}
	\item ``independent variable'' or ``feature'' and 
	\item ``dependent variable'', ``output variable'' or ``target''
\end{enumerate}}

\end{frame}


\begin{frame}{A little notation}
Moving forward, we'll use this notation and terminology:

\begin{eqnarray*}
x_i & i^\text{th} \text{ observation of an independent variable}\\
y_i & i^\text{th} \text{ observation of a dependent variable}\\
\epsilon_i & i^\text{th} \text{ random error, uncorrelated with }x_i,\text{ and mean zero}\\\\
y_i = f(x_i) + \epsilon_i & \text{ the ``true'' model, if one exists. }\\\\
\hat{y}_i = \hat{f}(x_i)  & \text{ our estimate of }y_i\text{ using an estimate of }f\\\end{eqnarray*}
\end{frame}

\begin{frame}{$\epsilon$ (epsilon) or $e$?}

\begin{eqnarray*}
y_i = f(x_i) + \epsilon_i & \text{ the ``true'' model, if one exists. }\\
y_i = \hat{f}(x_i) + e_i & \text{ the relationship between the data and the estimate. }
\end{eqnarray*}

\hspace{5mm}
\pause

So:
\begin{eqnarray*}
\epsilon_i&\text{variation in $y$ that is uncorrelated with $x$.}\\
e_i = y_i - \hat{f}(x_i) & \text{ the ``residual'' between the data and the estimate. }
\end{eqnarray*}

\end{frame}

\begin{frame}{$\epsilon$ (epsilon) v. $e$, continued}

Important!  
\begin{itemize}
\item $\epsilon$ and $e$ could be very different.  
\item Because we'll rarely know the ``true'' model, we'll rarely know $\epsilon$.
\item On average, $e$ will never be smaller than $\epsilon$
\end{itemize}
\end{frame}

\begin{frame}{How to evaluate how well a model performs? The \textit{Cost function.}}


\begin{itemize}
\item Cost functions can be used to describe how much of the variation in the data can be captured by the model.
\item Example: The mean squared error:

\pause 
\begin{align*}
MSE &= \frac{1}{n} ((y_1 - \hat{y}_1)^2 + (y_2 - \hat{y}_2)^2 + \cdots + (y_n - \hat{y}_n)^2) \\\\
&= \frac{1}{n} (e_1^2 + e_2^2 + \cdots + e_n^2) \\
&=\frac{1}{n} \sum_{i=1}^n e_i^2
\end{align*}
\end{itemize}

\pause
A major part of statistical learning lies in how the cost function is defined.

\end{frame}


\begin{frame}{A thought experiment from ISLR Ch 2}

\begin{columns}
\column{0.5\textwidth}
Suppose you have four different model forms to choose from.  When you fit them to the data, you get this figure.

\vspace{5mm}

Which model should you choose?  
\begin{itemize}
\item<2-> The one that minimizes mean squared error?
\item<3-> Careful!  Doesn't the squiggly one minimize mean squared error?
\item<4-> To do model selection we need to understand the concept of training and testing data.
\end{itemize}

\column{0.5\textwidth}
\includegraphics[scale=1]{figures/islr2_9a.pdf}
\end{columns}

\end{frame}

\begin{frame}{Concept:  Test and training data}


\begin{columns}
\column{0.65\textwidth}


Choosing between different models can be done by partitioning your data in to ``training'' and ``test'' data.

\begin{itemize}
\item ``Training data'': \only<2->{The data we use to choose the parameters of an individual model. }

\hspace{5mm}

\item ``Test data'': \only<2->{A set of data we withhold; it's not for training.  We use this data set to compare how different \textit{models} perform relative to one another.  }

\hspace{5mm}

\item<3-> Note: later in the course, we will talk about validation data for comparing completely different model forms.

\end{itemize}
\column{0.35\textwidth}

\only<2->{\includegraphics[scale=0.35]{figures/07_cross_validation_diagram}
\begin{tiny}
Source: kaggle.com
\end{tiny}}
\end{columns}


\end{frame}


\begin{frame}{MSE for test and training data}


\begin{columns}
\column{0.5\textwidth}


\includegraphics[scale=1]{figures/islr2_9a.pdf}


What might a plot of MSE versus model ``flexibility'' look like?


\column{0.5\textwidth}

\pause 
\includegraphics[scale=0.25]{figures/islr2_9b.pdf}
\end{columns}


\end{frame}



\begin{frame}{Bias v. Variance}

\textbf{Bias}: 
\begin{itemize}
\item The propensity for a model to produce errors that are systematically high or low
\item Bias can be positive in one range of the predictor and negative in another.  
\end{itemize}


\textbf{Variance}
\begin{itemize}
\item The propensity for a model to make very different predictions if it is fit with two different training data sets that are sampled from the same population.
\end{itemize}

\hspace{5mm}

\pause
Side note:  Total error can be decomposed:
\begin{align*}
\text{Avg }(y_0-\hat{f}(x_0))^2 = & \text{(variance in a prediction, across different training data)}\\
&+(\text{systematic bias})^2 + \text{(variance in }y\text{ that's uncorrelated with }x)\\
\onslide<2->{ =  &\text{var} (\hat{f}(x_0)) + [\text{bias}(\hat{f}(x_0))]^2+\text{var}(\epsilon_0)}
\end{align*}

\end{frame}


\begin{frame}{Bias v. Variance, ctd.}


\begin{columns}
\column{0.4\textwidth}

\includegraphics[scale=1]{figures/islr2_9a.pdf}

\column{0.6\textwidth}

Which model has the greatest propensity for bias? (Systematically high or low estimates)
\begin{itemize}
\item<2-> The linear one.  In ranges of $x$, it systematically under- or over-estimates. 
\end{itemize}

\hspace{5mm}

Which model has the greatest propensity for variance? (Different predictions if fit with different data sets)
\begin{itemize}
\item<3-> The squiggly one.  If we drew another sample of data, we'd probably get very different squiggles.
\end{itemize}
\end{columns}



\end{frame}

\begin{frame}{Decomposing bias-variance}

\begin{columns}
\column{0.375\textwidth}
\includegraphics[scale=0.25]{figures/islr2_9b.pdf}

\column{0.3\textwidth}
Take a moment to think about how bias and variance add up to make the red curve on the left.  Try to draw bias and variance separately.  

\column{0.3\textwidth}
\pause 
\includegraphics[scale=0.21]{figures/islr2_12a_text.pdf}

\end{columns}

\end{frame}


\begin{frame}{Bias variance tradeoff is one of the most important concepts we'll learn.}
    
As we learn to train different models, we'll always be seeking to balance these two sources of error.

\end{frame}


\begin{frame}{Linear regression}

\textbf{Regression:} A method to estimate the expected value of an output variable ($y$), \textit{conditional} on one or more input values ($x$)

\begin{itemize}
\item KNN regression (end of these slides, and in textbook) does this by averaging nearby values.

\item Linear regression does this by fitting a linear function to the data.

\item Broadly speaking, \textit{regression} can be used for prediction.

\item \textit{Linear} regression specifically can also be used for inference.

\item Many of the methods we'll work with later in the semester will be rooted in linear regression.
\end{itemize}

\end{frame}

\begin{frame}{The basic model}

\begin{itemize}
\item $x_i$: one dimensional independent variable 
\item $y_i$: one dimensional dependent variable
\end{itemize}

\begin{align*}
y_i &= \hat{\beta}_0 + \hat{\beta}_1 x_i + e_i\\
\hat{y_i} &= \hat{\beta}_0 + \hat{\beta}_1 x_i
\end{align*}

\begin{itemize}
\item We use the $\hat{\cdot}$ symbol to denote an estimate, or prediction
\end{itemize}
\end{frame}


\begin{frame}{(extremely important) Side note: Optimality.}


Define the ``argument'' that minimizes a function $f$ with respect to $\theta$ as:

\begin{align*}
\theta^* = \arg \min_{\theta} f(\theta)
\end{align*}

In the plot below, what's $\theta^*$?

\vspace{-8mm}

\begin{columns}
\column{0.5\textwidth}
\begin{center}
\includegraphics[scale=0.5]{figures/simple_min}
\end{center}

\column{0.5\textwidth}
\pause
\begin{align*}
\theta^* = \arg \min_{\theta} f(\theta) = 6\\
f(\theta^*) =10
\end{align*}

\end{columns}

\end{frame}

\begin{frame}{What do the minima share in common?}

\begin{columns}
\column{0.5\textwidth}
\includegraphics[scale=0.5]{figures/multiple_min}

\column{0.5\textwidth}
\pause
\begin{align*}
\frac{\partial f(\theta)}{\partial \theta}\Big|_{\theta^*} = 0
\end{align*}

\end{columns}
\end{frame}


\begin{frame}{What's the challenge here?}

\begin{columns}
\column{0.5\textwidth}
\includegraphics[scale=0.5]{figures/multiple_extrema}

\column{0.5\textwidth}
\pause
$\frac{\partial f(\theta)}{\partial \theta} = 0$ at more than one point.  

\vspace{5mm}

The function is said to be ``non-convex''

\vspace{5mm}

\pause
Which should we choose?

\begin{itemize}
\item We could enumerate all the solutions and choose the best.  
\pause
\item But that can get really tedious with complicated functions.
\end{itemize}

\end{columns}
\end{frame}


\begin{frame}{Estimation can be framed as an optimization problem}

In many forms of estimation, we set up the problem as follows:

\begin{align*}
\{\hat{\beta}_0, \hat{\beta}_1\} &= \arg \min_{\beta_0,\beta_1} J(\beta_0,\beta_1)
\end{align*}

...where $\beta$s are the parameters we wish to identify.  

\vspace{5mm}

In this course, we'll be looking at a broad variety of ways to define the \textit{cost function}, $J$.

\end{frame}

\begin{frame}{Linear regression as optimization}

In ``least squares'' linear regression, the starting point for estimation is

\begin{align*}
\{\hat{\beta}_0, \hat{\beta}_1\} &= \arg \min_{\beta_0,\beta_1} \sum_{i=1}^n (e_i)^2\\
\onslide<2->{&= \arg \min_{\beta_0,\beta_1} \sum_{i=1}^n (y_i - \hat{y}_i)^2}\\
\onslide<3->{&= \arg \min_{\beta_0,\beta_1} \sum_{i=1}^n (y_i - (\beta_0 + \beta_1 x_i))^2}\\
\end{align*}
\end{frame}

\begin{frame}{Why choose a quadratic (squared) objective function?}

\pause
Hint: 

\includegraphics[width=0.5\textwidth]{figures/simple_min.pdf}
\includegraphics[width=0.5\textwidth]{figures/multiple_extrema.pdf}

\pause

With least squares, the cost function
\begin{itemize}
\item Has one global minimum
\item Is differentiable -- we can write an equation for 
$\frac{\partial f(\theta)}{\partial \theta} = 0$
\end{itemize}

\end{frame}

\begin{frame}{Solving the estimation problem}

\begin{align*}
\{\hat{\beta}_0, \hat{\beta}_1\} &= \arg \min_{\beta_0,\beta_1} \sum_{i=1}^n (y_i - (\beta_0 + \beta_1 x_i))^2
\end{align*}

So the optimal parameters must satisfy:

\begin{align*}
\frac{\partial \sum_{i=1}^n (y_i - (\beta_0 + \beta_1 x_i))^2}{\partial \beta_0} &= 0\\\\
\frac{\partial  \sum_{i=1}^n(y_i - (\beta_0 + \beta_1 x_i))^2}{\partial \beta_1} &= 0
\end{align*}
\end{frame}

\begin{frame}{The solution: }

\begin{align*}
\frac{\partial  \sum_{i=1}^n(y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_i))^2}{\partial \hat{\beta}_0} = 0 \quad\quad &\Rightarrow \hat{\beta}_0  =\bar{y} - \hat{\beta}_1\bar{x}\\\\
\frac{\partial   \sum_{i=1}^n(y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_i))^2}{\partial \hat{\beta}_0} = 0 \quad\quad &\Rightarrow 
\hat{\beta}_1 = \frac{ \sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n (x_i-\bar{x})^2}
\end{align*}

\end{frame}

\begin{frame}{Parametric vs. non-parametric models}

The model examples we discussed so far are \textbf{parametric}, meaning they relate inputs to outputs with a mathematical function defined by parameters.  

\vspace{5mm}

But \textbf{non-parametric} models are also possible.  
\begin{itemize}
\item These don't use functions with coefficients
\item Instead the data \textit{become} the model
\end{itemize}

\vspace{5mm}

It's easiest to see this by example using the K-nearest neighbors algorithm.

\end{frame}

\begin{frame}{K-nearest neighbors (KNN)}

 We'll work with just a one-dimensional independent variable. For example, 
\begin{itemize}
\item $y_i$ could be NOx emissions from a power plant, 
\item $x_i$ could be its coal use; 
\item different $i$ would correspond to different power plants in different years.
\end{itemize}

\vspace{5mm}
Definitions:
\begin{itemize}
\item First, define proximity between two points as $|x_i-x_j|$
\item Next, define $\mathcal{N}_i$ as the set of $K$ points closest to $x_i$ 
\end{itemize}

\end{frame}

\begin{frame}{K-nearest neighbors}
The basic idea behind using KNN for regression (i.e. predicting a continuous variable or set of variables) is simple:

\begin{align*}
\hat{y}_j = \frac{1}{K} \sum_{i\in \mathcal{N}_j} y_i
\end{align*}

In other words, the prediction equals the average of the $K$ nearest points.
\end{frame}

\begin{frame}{If you're working with KNN, what is your most important decision?}

\pause

\begin{center}
What is $K$?
\end{center}

Check of intuition:  Would increasing $K$ reduce or increase bias?\pause \textbf{  Increase!}

\begin{itemize}
\item Using a lower $K$ would cause the estimates to more closely follow the underlying data.  
\item In the extreme, $K=1$ would make the model equal the underlying data.
\item At the other extreme, $K=n$ would make the model equal the sample mean.
\end{itemize}
\end{frame}



\end{document}


