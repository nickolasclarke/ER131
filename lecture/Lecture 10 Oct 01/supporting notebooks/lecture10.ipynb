{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('BechleLUR_2006_allmodelbuildingdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_all.columns:\n",
    "    print(i,end=\"\\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Which variables would be a bad idea to include in the model?  That is, before we try to do any model selection, what's obviously out?\n",
    "\n",
    "Now let's build some models.\n",
    "\n",
    "First let's try regressing observed NO2 against the satellite measuremenets (you'll do this in HW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very important note: scikit-learn wants a data frame for the predictors -- if you have only one predictor and you pass in a pandas series, scikit-learn throws an error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df_all.loc[:,['WRF+DOMINO']]\n",
    "output = df_all['Observed_NO2_ppb']\n",
    "lm.fit(predictors, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('slope is',lm.coef_[0])\n",
    "print('intercept is',lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = lm.predict(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(output,y_hat)\n",
    "plt.xlabel('Observed NO2')\n",
    "plt.ylabel('Predicted NO2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(predictors, output-y_hat)\n",
    "plt.xlabel('Satellite NO2')\n",
    "plt.ylabel('Residual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the regression results using a different package called statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a nice feature in statsmodels that allows you to add a constant to a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_const = sm.add_constant(predictors)\n",
    "predictors_const.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = sm.OLS(output, predictors_const)\n",
    "est_fit = est.fit()\n",
    "print(est_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try estimating a model with **all** the predictors embedded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_all = df_all.loc[:,'WRF+DOMINO':'total_14000']\n",
    "predictors_all_const = sm.add_constant(predictors_all)\n",
    "est_all = sm.OLS(output, predictors_all_const)\n",
    "est_all_fit = est_all.fit()\n",
    "print(est_all_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at what happens if we drop some of the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_less = df_all.loc[:,'WRF+DOMINO':'Resident_100']\n",
    "predictors_less_const = sm.add_constant(predictors_less)\n",
    "est_less = sm.OLS(output, predictors_less_const)\n",
    "est_less_fit = est_less.fit()\n",
    "print(est_less_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to note:\n",
    "1. AIC is lower for \\*\\_less.  \\*\\_all does a better job of reducing squared error, but it gets penalized more for having more variables.\n",
    "2. Look at the p-values and confidence intervals.  You can see that p-values are big (>0.05) when confidence intervals span zero.  \n",
    "3. Resident_100 was insignificant when included with lots of other Resident_\\* variables, but on it's own it is strongly significant.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
