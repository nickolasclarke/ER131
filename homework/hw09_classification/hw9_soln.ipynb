{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\" # put your full name here\n",
    "COLLABORATORS = [] # list names of anyone you worked with on this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ERG 131] Homework 9: Classification\n",
    "----\n",
    "\n",
    "This homework will build on the methods introduced in lab 9 that predict qualitative variables. Besides logistic regression and KNN, which were explored in lab 9, decision trees are another powerful prediction method and are easy to interpret. A decision tree can explain exactly why a specific prediction was made. As we'll see in this lab, using a single decision tree to make a prediction often isn't the best performing method. However, ensemble methods such as random forests and bagging use multiple trees to reach a \"consensus\" decision, and typically perform better than single decision trees. In this homework, we'll start by building a single decision tree and then see how ensemble methods perform by comparison.\n",
    "\n",
    "Trees are, overall, a relatively accessible method for predictive modeling since they are used for both regression and classification and can take in both continuous and categorical data. Decision trees are covered in sections 8.1-8.3 of ISLR.\n",
    "\n",
    "In this homework, we'll be doing a brief exploration of the CalEnviroScreen dataset, testing out how to make a tree from scratch, as well as implementing various ensemble methods using scikit-learn. It'll be a comprehensive survey of trees and the multitude of algorithms that arise from one tree!\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [The data](#data) <br>\n",
    "1. [Decision trees from scratch](#scratch) <br>\n",
    "1. [Implementing decision trees with scikit-learn](#sk) <br>\n",
    "1. [Ensemble methods](#improve) <br>\n",
    "1. [Project](#project)\n",
    "\n",
    "**Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "import urllib\n",
    "import os.path\n",
    "from shutil import copyfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd\n",
      "  Using cached https://files.pythonhosted.org/packages/b0/16/63576a1a001752e34bf8ea62e367997530dc553b689356b9879339cf45a4/xlrd-1.2.0-py2.py3-none-any.whl\n",
      "Installing collected packages: xlrd\n",
      "Successfully installed xlrd-1.2.0\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting graphviz\n",
      "  Using cached https://files.pythonhosted.org/packages/f5/74/dbed754c0abd63768d3a7a7b472da35b08ac442cf87d73d5850a6f32391e/graphviz-0.13.2-py2.py3-none-any.whl\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.13.2\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "!pip install xlrd\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: The data <a name='data'></a>\n",
    "\n",
    "In this homework, we will be working with the [California Communities Environmental Health Screening Tool (CalEnviroScreen)](https://oehha.ca.gov/calenviroscreen/report/calenviroscreen-30), which uses demographic and environmental information to identify communities that are susceptible to various types of pollution. The various variables in this dataset contribute to the CES score, which reflects a community's environmental conditions and its vulnerability to environmental pollutants.\n",
    "\n",
    "Although this dataset scores around 8000 of census tracts in California, we'll focus on a subset which makes the decision tree slightly more interpretable. \n",
    "\n",
    "Your HW9 folder contains an Excel file downloaded from [here](https://oehha.ca.gov/media/downloads/calenviroscreen/document/ces3results.xlsx).\n",
    "\n",
    "Documentation on Pandas' Excel methods can be found [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html#pandas.read_excel). Start by running the cell below, which creates an Excel file object in Pandas that we can then inspect. The cell below shows you the sheet names in the spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CES 3.0 (2018 Update)', 'Data Dictionary', 'Missing&NAData', 'Demographic profile']\n"
     ]
    }
   ],
   "source": [
    "# run this cell\n",
    "filename = 'ces3results.xlsx'\n",
    "xl = pd.ExcelFile(filename)\n",
    "print(xl.sheet_names) # display a list of the sheets in the spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1** Load the first sheet of the Excel file and assign it to the variable `df0`. If you're unsure of where to start, look at the link above to documentation on Excel methods in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>California County</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>Nearby City \n",
       "(to help approximate location only)</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>CES 3.0 Score</th>\n",
       "      <th>CES 3.0 Percentile</th>\n",
       "      <th>CES 3.0 \n",
       "Percentile Range</th>\n",
       "      <th>...</th>\n",
       "      <th>Linguistic Isolation Pctl</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Poverty Pctl</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Unemployment Pctl</th>\n",
       "      <th>Housing Burden</th>\n",
       "      <th>Housing Burden Pctl</th>\n",
       "      <th>Pop. Char.</th>\n",
       "      <th>Pop. Char. Score</th>\n",
       "      <th>Pop. Char. Pctl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6019001100</td>\n",
       "      <td>3174</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93706</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.781696</td>\n",
       "      <td>36.709695</td>\n",
       "      <td>94.090246</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>77.509665</td>\n",
       "      <td>76.3</td>\n",
       "      <td>97.121307</td>\n",
       "      <td>17.6</td>\n",
       "      <td>91.724838</td>\n",
       "      <td>26.0</td>\n",
       "      <td>79.398324</td>\n",
       "      <td>92.120494</td>\n",
       "      <td>9.553509</td>\n",
       "      <td>99.697314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6071001600</td>\n",
       "      <td>6133</td>\n",
       "      <td>San Bernardino</td>\n",
       "      <td>91761</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>-117.618013</td>\n",
       "      <td>34.057780</td>\n",
       "      <td>90.677839</td>\n",
       "      <td>99.987388</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>96.253833</td>\n",
       "      <td>72.5</td>\n",
       "      <td>94.632307</td>\n",
       "      <td>12.3</td>\n",
       "      <td>71.823836</td>\n",
       "      <td>34.1</td>\n",
       "      <td>93.754760</td>\n",
       "      <td>87.436849</td>\n",
       "      <td>9.067784</td>\n",
       "      <td>98.108210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6019000200</td>\n",
       "      <td>3167</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93706</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.805504</td>\n",
       "      <td>36.735491</td>\n",
       "      <td>85.970036</td>\n",
       "      <td>99.974776</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>78.389548</td>\n",
       "      <td>86.8</td>\n",
       "      <td>99.560025</td>\n",
       "      <td>16.1</td>\n",
       "      <td>87.980708</td>\n",
       "      <td>40.1</td>\n",
       "      <td>97.854785</td>\n",
       "      <td>94.581328</td>\n",
       "      <td>9.808714</td>\n",
       "      <td>99.987388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077000801</td>\n",
       "      <td>6692</td>\n",
       "      <td>San Joaquin</td>\n",
       "      <td>95203</td>\n",
       "      <td>Stockton</td>\n",
       "      <td>-121.314524</td>\n",
       "      <td>37.940517</td>\n",
       "      <td>82.491521</td>\n",
       "      <td>99.962164</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>75.136648</td>\n",
       "      <td>61.3</td>\n",
       "      <td>85.568825</td>\n",
       "      <td>19.6</td>\n",
       "      <td>94.973981</td>\n",
       "      <td>21.1</td>\n",
       "      <td>63.544047</td>\n",
       "      <td>86.701266</td>\n",
       "      <td>8.991499</td>\n",
       "      <td>97.717241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6019001500</td>\n",
       "      <td>2206</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93725</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.717843</td>\n",
       "      <td>36.681600</td>\n",
       "      <td>82.030814</td>\n",
       "      <td>99.949552</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>73.723504</td>\n",
       "      <td>66.4</td>\n",
       "      <td>90.232558</td>\n",
       "      <td>18.6</td>\n",
       "      <td>93.654017</td>\n",
       "      <td>28.1</td>\n",
       "      <td>83.980706</td>\n",
       "      <td>80.075199</td>\n",
       "      <td>8.304332</td>\n",
       "      <td>92.760752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Census Tract  Total Population California County    ZIP  \\\n",
       "0    6019001100              3174           Fresno   93706   \n",
       "1    6071001600              6133    San Bernardino  91761   \n",
       "2    6019000200              3167           Fresno   93706   \n",
       "3    6077000801              6692       San Joaquin  95203   \n",
       "4    6019001500              2206           Fresno   93725   \n",
       "\n",
       "  Nearby City \\n(to help approximate location only)   Longitude   Latitude  \\\n",
       "0                                            Fresno -119.781696  36.709695   \n",
       "1                                           Ontario -117.618013  34.057780   \n",
       "2                                            Fresno -119.805504  36.735491   \n",
       "3                                          Stockton -121.314524  37.940517   \n",
       "4                                            Fresno -119.717843  36.681600   \n",
       "\n",
       "   CES 3.0 Score   CES 3.0 Percentile CES 3.0 \\nPercentile Range  \\\n",
       "0      94.090246           100.000000   95-100% (highest scores)   \n",
       "1      90.677839            99.987388   95-100% (highest scores)   \n",
       "2      85.970036            99.974776   95-100% (highest scores)   \n",
       "3      82.491521            99.962164   95-100% (highest scores)   \n",
       "4      82.030814            99.949552   95-100% (highest scores)   \n",
       "\n",
       "        ...        Linguistic Isolation Pctl  Poverty  Poverty Pctl  \\\n",
       "0       ...                        77.509665     76.3     97.121307   \n",
       "1       ...                        96.253833     72.5     94.632307   \n",
       "2       ...                        78.389548     86.8     99.560025   \n",
       "3       ...                        75.136648     61.3     85.568825   \n",
       "4       ...                        73.723504     66.4     90.232558   \n",
       "\n",
       "   Unemployment  Unemployment Pctl  Housing Burden  Housing Burden Pctl  \\\n",
       "0          17.6          91.724838            26.0            79.398324   \n",
       "1          12.3          71.823836            34.1            93.754760   \n",
       "2          16.1          87.980708            40.1            97.854785   \n",
       "3          19.6          94.973981            21.1            63.544047   \n",
       "4          18.6          93.654017            28.1            83.980706   \n",
       "\n",
       "   Pop. Char.   Pop. Char. Score  Pop. Char. Pctl  \n",
       "0    92.120494          9.553509        99.697314  \n",
       "1    87.436849          9.067784        98.108210  \n",
       "2    94.581328          9.808714        99.987388  \n",
       "3    86.701266          8.991499        97.717241  \n",
       "4    80.075199          8.304332        92.760752  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "df0 = xl.parse(xl.sheet_names[0]) # display the first sheet as Pandas dataframe\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we explore this dataset, look at some of the features -- notice that this dataset doesn't include the units of most of its features. Let's take a look at a different sheet.\n",
    "\n",
    "Run the following cell to load the data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>CalEnviroScreen Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Census Tract</td>\n",
       "      <td>Census Tract ID from 2010 Census</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total Population</td>\n",
       "      <td>2010 population in census tracts</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>California County</td>\n",
       "      <td>California county that the census tract falls ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZIP</td>\n",
       "      <td>Postal ZIP Code that the census tract falls wi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nearby City \\n(to help approximate location only)</td>\n",
       "      <td>City or nearby city the  census tract falls wi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>Longitude of the centroid of the census tract</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>Latitude of the centroid of the census tract</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CES 3.0 Score</td>\n",
       "      <td>CalEnviroScreen Score, Pollution Score multipl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CES 3.0 Percentile</td>\n",
       "      <td>Percentile of the CalEnviroScreen score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CES 3.0 Percentile Range</td>\n",
       "      <td>Percentile of the CalEnviroScreen score, group...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Variable Name  \\\n",
       "0                                       Census Tract   \n",
       "1                                   Total Population   \n",
       "2                                  California County   \n",
       "3                                                ZIP   \n",
       "4  Nearby City \\n(to help approximate location only)   \n",
       "5                                          Longitude   \n",
       "6                                           Latitude   \n",
       "7                                      CES 3.0 Score   \n",
       "8                                 CES 3.0 Percentile   \n",
       "9                           CES 3.0 Percentile Range   \n",
       "\n",
       "                                         Description CalEnviroScreen Category  \n",
       "0                   Census Tract ID from 2010 Census                      NaN  \n",
       "1                  2010 population in census tracts                       NaN  \n",
       "2  California county that the census tract falls ...                      NaN  \n",
       "3  Postal ZIP Code that the census tract falls wi...                      NaN  \n",
       "4  City or nearby city the  census tract falls wi...                      NaN  \n",
       "5      Longitude of the centroid of the census tract                      NaN  \n",
       "6       Latitude of the centroid of the census tract                      NaN  \n",
       "7  CalEnviroScreen Score, Pollution Score multipl...                      NaN  \n",
       "8            Percentile of the CalEnviroScreen score                      NaN  \n",
       "9  Percentile of the CalEnviroScreen score, group...                      NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = xl.parse('Data Dictionary', header = 6)\n",
    "dd.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, let's check the sheet we just loaded. \n",
    "\n",
    "**Question 1.2** Does the number of columns in the first sheet (loaded to `df0`) correspond with the number of variables in the data dictionary? Your answer should return a boolean value.\n",
    "\n",
    "*Hint:* There are more rows in the `dd` than there are variables defined in that dictionary! You should inspect the dataframe `dd` to see why that is, and write your Boolean expression so that it considers the number of variable names in `dd` rather than the number of rows in `dd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SOLUTION\n",
    "dd[dd[\"Variable Name\"].notnull()].shape[0] == df0.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data for Alameda County.\n",
    "\n",
    "**Question 1.3** Find all instances that Alameda County appears in the dataset and assign it to the variable `alameda`. Then, select the columns `Census Tract`, `ZIP`, `CES 3.0 Score`, `Housing Burden`, `Poverty`, `Pesticides`, `Groundwater Threats`, and `Pollution Burden`, and assign the resulting table to `alameda_ft`.\n",
    "\n",
    "*Hint:* Before you subset the dataframe `df0`, you will want to perform some data cleaning to remove trailing and leading spaces from the county names.  There is a `pandas` method that will do that for you automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>CES 3.0 Score</th>\n",
       "      <th>Housing Burden</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Pesticides</th>\n",
       "      <th>Groundwater Threats</th>\n",
       "      <th>Pollution Burden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>6001409000</td>\n",
       "      <td>94621</td>\n",
       "      <td>61.560437</td>\n",
       "      <td>32.5</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.50</td>\n",
       "      <td>57.413064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>6001409100</td>\n",
       "      <td>94603</td>\n",
       "      <td>59.868084</td>\n",
       "      <td>29.5</td>\n",
       "      <td>55.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.10</td>\n",
       "      <td>54.143340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>6001408800</td>\n",
       "      <td>94621</td>\n",
       "      <td>59.647241</td>\n",
       "      <td>35.2</td>\n",
       "      <td>66.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.65</td>\n",
       "      <td>50.360950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>6001409200</td>\n",
       "      <td>94603</td>\n",
       "      <td>55.292008</td>\n",
       "      <td>27.4</td>\n",
       "      <td>44.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>54.957476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>6001407300</td>\n",
       "      <td>94601</td>\n",
       "      <td>52.539247</td>\n",
       "      <td>21.4</td>\n",
       "      <td>56.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.05</td>\n",
       "      <td>56.830015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>6001409500</td>\n",
       "      <td>94621</td>\n",
       "      <td>51.441952</td>\n",
       "      <td>27.6</td>\n",
       "      <td>64.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.85</td>\n",
       "      <td>44.367354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>6001406000</td>\n",
       "      <td>94606</td>\n",
       "      <td>50.284331</td>\n",
       "      <td>31.0</td>\n",
       "      <td>61.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.80</td>\n",
       "      <td>52.302911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>6001402200</td>\n",
       "      <td>94607</td>\n",
       "      <td>49.455273</td>\n",
       "      <td>29.3</td>\n",
       "      <td>56.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.25</td>\n",
       "      <td>54.195855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>6001409400</td>\n",
       "      <td>94603</td>\n",
       "      <td>49.223471</td>\n",
       "      <td>35.9</td>\n",
       "      <td>65.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.05</td>\n",
       "      <td>44.346600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>6001408900</td>\n",
       "      <td>94621</td>\n",
       "      <td>47.973012</td>\n",
       "      <td>41.6</td>\n",
       "      <td>73.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.30</td>\n",
       "      <td>45.360316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Census Tract    ZIP  CES 3.0 Score  Housing Burden  Poverty  Pesticides  \\\n",
       "245     6001409000  94621      61.560437            32.5     52.5         0.0   \n",
       "287     6001409100  94603      59.868084            29.5     55.8         0.0   \n",
       "300     6001408800  94621      59.647241            35.2     66.5         0.0   \n",
       "517     6001409200  94603      55.292008            27.4     44.4         0.0   \n",
       "701     6001407300  94601      52.539247            21.4     56.3         0.0   \n",
       "769     6001409500  94621      51.441952            27.6     64.2         0.0   \n",
       "862     6001406000  94606      50.284331            31.0     61.9         0.0   \n",
       "926     6001402200  94607      49.455273            29.3     56.8         0.0   \n",
       "950     6001409400  94603      49.223471            35.9     65.7         0.0   \n",
       "1056    6001408900  94621      47.973012            41.6     73.5         0.0   \n",
       "\n",
       "      Groundwater Threats  Pollution Burden  \n",
       "245                118.50         57.413064  \n",
       "287                 25.10         54.143340  \n",
       "300                 37.65         50.360950  \n",
       "517                 28.00         54.957476  \n",
       "701                183.05         56.830015  \n",
       "769                 40.85         44.367354  \n",
       "862                144.80         52.302911  \n",
       "926                137.25         54.195855  \n",
       "950                 56.05         44.346600  \n",
       "1056                31.30         45.360316  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "df0[\"California County\"] = df0[\"California County\"].str.strip()\n",
    "alameda = df0[df0['California County'] == 'Alameda']\n",
    "alameda_ft = alameda[['Census Tract', 'ZIP', 'CES 3.0 Score', 'Housing Burden', 'Poverty', \n",
    "                        'Pesticides', 'Groundwater Threats', 'Pollution Burden']]\n",
    "alameda_ft.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert alameda_ft.shape == (360,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare two rows in our table -- specifically the rows with Census Tract `6001421100` and `6001422000`. Run the following cell to load the two rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>CES 3.0 Score</th>\n",
       "      <th>Housing Burden</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Pesticides</th>\n",
       "      <th>Groundwater Threats</th>\n",
       "      <th>Pollution Burden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>6001421100</td>\n",
       "      <td>94708</td>\n",
       "      <td>1.473144</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.788499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>6001422000</td>\n",
       "      <td>94710</td>\n",
       "      <td>39.951507</td>\n",
       "      <td>8.8</td>\n",
       "      <td>41.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>58.519327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Census Tract    ZIP  CES 3.0 Score  Housing Burden  Poverty  Pesticides  \\\n",
       "7918    6001421100  94708       1.473144            11.7      7.9         0.0   \n",
       "1908    6001422000  94710      39.951507             8.8     41.5         0.0   \n",
       "\n",
       "      Groundwater Threats  Pollution Burden  \n",
       "7918                  0.0         15.788499  \n",
       "1908                236.0         58.519327  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind1 = alameda_ft[alameda_ft['Census Tract'] == 6001421100.0]\n",
    "ind2 = alameda_ft[alameda_ft['Census Tract'] == 6001422000.0]\n",
    "ind1.append(ind2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two communities are extremely different -- one has an extremely low score and one has a high score, and the values in the features are also pretty varied. Let's take a look at where their scores lie in various histograms of the features.\n",
    "\n",
    "**Question 1.4:** Plot two distributions, one for the `Poverty` for all Alameda tracts and one for `Pollution Burden`. Along with these histograms, mark the points at which the two tracts above lie within the distribution (you can use a vertical line in a different color from the histogram bins, as we have in previous labs and homeworks). \n",
    "\n",
    "Use a legend or [text](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.text.html) to indicate which line corresponds to which census tract - you can call the tract with data in `ind1` \"Census tract 1\", and the tract with data in `ind2` \"Census tract 2\". Add a title and axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/app/venv/lib/python3.6/site-packages/numpy/lib/histograms.py:824: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/srv/app/venv/lib/python3.6/site-packages/numpy/lib/histograms.py:825: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SOLUTION (poverty hist)\n",
    "plt.figure(figsize = (15,7))\n",
    "\n",
    "plots = ['Poverty', 'Pollution Burden']\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.hist(alameda_ft[plots[i]])\n",
    "    plt.xlim(0,75)\n",
    "    plt.ylim(0,90)\n",
    "    plt.axvline(ind1[plots[i]].values, c = 'y')\n",
    "    plt.text(ind1[plots[i]].values-3, 50, \"Census tract 1\", fontsize = 10, rotation = 90)\n",
    "    plt.axvline(ind2[plots[i]].values, c = 'y')\n",
    "    plt.text(ind2[plots[i]].values-3, 50, \"Census tract 2\", fontsize = 10, rotation = 90)\n",
    "    plt.title(plots[i] + \" distribution, Alameda County\", fontsize = 14)\n",
    "    plt.xlabel(plots[i] + \" indicator\")\n",
    "    plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's take a look at the demographic profiles of these two communities. This data is stored in the `Demographic profile` sheet.\n",
    "\n",
    "**Question 1.5** Similar to what we did earlier by comparing the two rows, compare the two tracts' demographic information (i.e. display the two rows together). We've loaded the sheet into a dataframe `dp` and have renamed the columns for you. In the cell below, load the demographic data corresponding to the first census tract in `demo1`, and the data corresponding to the second in `demo2`, much like we did right before question 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load demographic profile\n",
    "dp = xl.parse('Demographic profile', header = 1)\n",
    "dp = dp.reset_index()\n",
    "dp = dp.rename(columns = {'level_0': 'Census Tract',\n",
    "                          'level_1': 'CES 3.0 Score',\n",
    "                          'level_2': 'CES 3.0 Percentile',\n",
    "                          'level_3': 'CES 3.0 Percentile Range',\n",
    "                          'level_4': 'Total Population',\n",
    "                          'level_5': 'California County'\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>CES 3.0 Score</th>\n",
       "      <th>CES 3.0 Percentile</th>\n",
       "      <th>CES 3.0 Percentile Range</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>California County</th>\n",
       "      <th>Children &lt; 10 (%)</th>\n",
       "      <th>Pop 11-64 years (%)</th>\n",
       "      <th>Elderly &gt; 65 (%)</th>\n",
       "      <th>Hispanic (%)</th>\n",
       "      <th>White (%)</th>\n",
       "      <th>African American (%)</th>\n",
       "      <th>Native American (%)</th>\n",
       "      <th>Asian American (%)</th>\n",
       "      <th>Other (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>6001421100</td>\n",
       "      <td>1.473144</td>\n",
       "      <td>0.138731</td>\n",
       "      <td>1-5% (lowest scores)</td>\n",
       "      <td>1992</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>9.5</td>\n",
       "      <td>63.3</td>\n",
       "      <td>27.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>6001422000</td>\n",
       "      <td>39.951507</td>\n",
       "      <td>75.936436</td>\n",
       "      <td>75-80%</td>\n",
       "      <td>1756</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>9.1</td>\n",
       "      <td>82.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>12.6</td>\n",
       "      <td>43.3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Census Tract  CES 3.0 Score  CES 3.0 Percentile  \\\n",
       "7918    6001421100       1.473144            0.138731   \n",
       "1908    6001422000      39.951507           75.936436   \n",
       "\n",
       "     CES 3.0 Percentile Range  Total Population California County  \\\n",
       "7918     1-5% (lowest scores)              1992          Alameda    \n",
       "1908                   75-80%              1756          Alameda    \n",
       "\n",
       "      Children < 10 (%)  Pop 11-64 years (%)  Elderly > 65 (%)  Hispanic (%)  \\\n",
       "7918                9.5                 63.3              27.2           5.0   \n",
       "1908                9.1                 82.5               8.4          12.6   \n",
       "\n",
       "      White (%)  African American (%)  Native American (%)  \\\n",
       "7918       76.5                   1.8                  0.0   \n",
       "1908       43.3                  28.0                  0.2   \n",
       "\n",
       "      Asian American (%)  Other (%)  \n",
       "7918                12.0        4.6  \n",
       "1908                10.0        5.9  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "demo1 = dp[dp['Census Tract'] == 6001421100.0]\n",
    "demo2 = dp[dp['Census Tract'] == 6001422000.0]\n",
    "demo1.append(demo2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're curious, you can take a look at where these census tracts are located by inputting the coordinates in [maps](https://www.google.com/maps).\n",
    "- Coordinates for the first row: (+37.8994340, -122.2661928)\n",
    "- Coordinates for second row: (+37.8590327, -122.3013426)\n",
    "\n",
    "You can also use this [web tool](https://data.cityofberkeley.info/Demographics/Census-Tract-Polygons-2010/peq3-2arw) provided by the city of Berkeley to look at the area of each tract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Section 2: A decision tree from scratch <a name = 'scratch'></a>\n",
    "\n",
    "Now that we've explored three different sheets in our original Excel file and are familiar with the data, we can move on to creating a decision tree from scratch. Even though trees are pretty easy to interpret, there's a lot that runs to create the final tree. We'll walk through creating a tree which will hopefully help our intuition when we use scikit-learn later in this homework.\n",
    "\n",
    "First, let's take a very small subset of our data so that our tree will be easy to work with. There are a few things that we're going to do here to make this process more digestible -- we're taking a sample of 10 from the table and we are classifying the top and bottom groups of the CES dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1** In this section, we'll go back to the dataframe `df0` (rather than looking at just the Alameda County data). In the cell below, we have one data-cleaning line that renames one of the columns we're going to use in building our decision tree - the percentile range of a given census tract. Then, we ouput the unique values for percentile range so that you can inspect the column.\n",
    "\n",
    "In the cell below, you should create a new dataframe, `extremes`. It should contain data for tracts with the highest percentile score and lowest percentile score. For simplicity, your dataframe should only contain 3 columns: \"Groundwater Threats\", \"Drinking Water\", and \"CES 3.0 Percentile Range\".\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['95-100% (highest scores)', '90-95%', '85-90%', '80-85%', '75-80%',\n",
       "       '70-75%', '65-70%', '60-65%', '55-60%', '50-55%', '45-50%',\n",
       "       '40-45%', '35-40%', '30-35%', '25-30%', '20-25%', '15-20%',\n",
       "       '10-15%', '5-10%', '1-5% (lowest scores)', nan], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell\n",
    "df0.rename(columns={'CES 3.0 \\nPercentile Range':'CES 3.0 Percentile Range'}, inplace = True)\n",
    "df0['CES 3.0 Percentile Range'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Groundwater Threats</th>\n",
       "      <th>Drinking Water</th>\n",
       "      <th>CES 3.0 Percentile Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.75</td>\n",
       "      <td>681.195604</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.00</td>\n",
       "      <td>904.657603</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.25</td>\n",
       "      <td>681.195604</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132.10</td>\n",
       "      <td>278.756235</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.20</td>\n",
       "      <td>1000.240794</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Groundwater Threats  Drinking Water  CES 3.0 Percentile Range\n",
       "0                45.75      681.195604  95-100% (highest scores)\n",
       "1                36.00      904.657603  95-100% (highest scores)\n",
       "2                30.25      681.195604  95-100% (highest scores)\n",
       "3               132.10      278.756235  95-100% (highest scores)\n",
       "4                54.20     1000.240794  95-100% (highest scores)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extremes = df0[(df0['CES 3.0 Percentile Range'] == '95-100% (highest scores)') \n",
    "               | (df0['CES 3.0 Percentile Range'] == '1-5% (lowest scores)')]\n",
    "\n",
    "extremes = extremes[[\"Groundwater Threats\", \"Drinking Water\",\"CES 3.0 Percentile Range\"]]\n",
    "\n",
    "extremes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert extremes.shape == (793, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can probably guess from the dataframe `extremes`, we're going to build a tree that decides whether a census tract is in the lowest or highest percentile range of CalEnviroScreen scores based on the value of its Groundwater Threats and Drinking Water metrics.\n",
    "\n",
    "When we build a tree, intuitively the first thing we need to do is decide how we'll create each split in the tree. In this section, we'll use the same criterion that scikit-learn uses when checking the \"quality\" of a split: the Gini index (also called Gini impurity). A low Gini index score indicates a near perfect split, and a high score means the composition of classes is nearly the same in both groups.\n",
    "\n",
    "What does that mean? Let's say we create a split where any census tracts where Groundwater Threats < 3 are on one branch (branch #1), and any census tracts where Groundwater Threats are >= 3 are on another branch (branch #2). If branch #1 consists of only tracts in the highest percentile range, and branch #2 consists of only tracts in the lowest percentile range, this is a perfect split and will get a low Gini index for both branches. However, if branch #1 has a 50/50 split of tracts, and so does branch #2 (i.e. there are both high percentile and low percentile tracts with Groundwater Threats >= 3), then this is a pretty bad split that doesn't really help with classification, and it will get a high Gini index score for both branches.\n",
    "\n",
    "The Gini index is calculated as follows:\n",
    "\n",
    "$$ G = \\sum_{k = 1}^{K}{\\hat{p}_k(1 - \\hat{p}_k)} = 1- \\sum_{k = 1}^{K} (\\hat{p}^2_k)$$\n",
    "\n",
    "where $G$ is the Gini index, and $\\hat{p}_k$ is the proportion of each response class in a split, and $K$ is the total number of response classes.\n",
    "\n",
    "A separate Gini index is calculated for each branch of a split, and then a weighted Gini index can be calculated for the overall split, where the weight corresponds to the number of observations in each split.\n",
    "\n",
    "**Question 2.2** Let's say we create a tree with one split, predicting a response variable with 2 classes (class 1 and class 2). We have 20 observations in total. One of the tree branches (branch #1) encompasses 3 observations of class 1 and 7 observations of class 2. The other tree branch (branch #2) encompasses 6 observations of class 1 and 4 observations of class 2. Calculate: \n",
    "1. The Gini index for branch #1\n",
    "1. The Gini index for branch #2\n",
    "1. The weighted Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch 1: 0.4200000000000001\n",
      "branch 2: 0.48\n",
      "weighted: 0.45000000000000007\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "gini1 = 1-(3/10)**2-(7/10)**2\n",
    "gini2 = 1-(6/10)**2-(4/10)**2\n",
    "ginitotal = 0.5*gini1 + 0.5*gini2\n",
    "print(\"branch 1:\", gini1)\n",
    "print(\"branch 2:\", gini2)\n",
    "print(\"weighted:\", ginitotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3** Take a look at the following cell, which contains the code to calculate the gini index. There are letters following three pound symbols. Write down what the lines of code below each letter are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(groups, classes):\n",
    "    ### A ###\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    ### B ###\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        ### C ###\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        ### D ###\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***solution***\n",
    "- a) count samples at split point\n",
    "- b) sum weighted Gini index for each group\n",
    "- c) score the group based on the score for each class\n",
    "- d) weight the group score by its relative size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "Now, we can work towards creating a split. Ultimately, we'll want to evaluate a range of possible splits using the Gini index. For now, we need a function that creates one split.\n",
    "\n",
    "Splitting a dataset means separating a dataset into two lists based on how a feature (with a column number indicated by `index`) compare to a value (`value`). Once we have the two lists, we can use the Gini index above to evaluate the cost of the split, which will be implemented in a later function.\n",
    "\n",
    "Run the following cell to load the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4** What does the group sorted in the right list represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**:  the right group contains all rows with a value at the index above or equal to the split value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "We can create our splits now. Given a dataset, we must check every value on each feature as a candidate split, evaluate the cost of the split using the Gini index and find the best possible split we can make. The lowest Gini score across all the features would then be chosen as the best split and a node would be created.\n",
    "\n",
    "We will use a dictionary to represent a node in the decision tree. When selecting the best split and using it as a new node for the tree we will store the index of the chosen attribute, the value of that attribute by which to split and the two groups of data split by the chosen split point.\n",
    "\n",
    "The function below runs this procedure. Run the cell to load function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < b_score:\n",
    "                b_index = index\n",
    "                b_value = row[index]\n",
    "                b_score = gini\n",
    "                b_groups = groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all of the tools to find the best splits of the tree -- let's see how we can use them to *build* one from the ground up (or from the top since trees are inverted...). \n",
    "\n",
    "Building a tree takes two main steps: finding leaves (e.g. when to stop the tree) and recursively splitting the tree.\n",
    "\n",
    "The following cell contains the function that returns the most common output in a list of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "We're almost there! The following cell contains the function that performs the recursive splitting. \n",
    "\n",
    "Here are the steps of this procedure:\n",
    "\n",
    "1. `split()` takes `node` as input, which is the dictionary returned by `get_split()`. The two lists of data returned by `get_split()` are extracted and deleted from the node. The node no longer requires access to these data.\n",
    "2. We check if either left or right group of rows is empty and if so we create a terminal node using the data and computed scores we have.\n",
    "3. Check if we have reached our maximum depth. If we have, create a terminal node.\n",
    "4. If the left group of rows is too small, we process the left child and create a terminal node. Otherwise, we create and add the left node in a depth-first fashion until the bottom of the tree is reached on this branch.\n",
    "5. Right side is then processed in the same manner, as we rise back up the constructed tree to the root.\n",
    "\n",
    "**Question 2.5** Similar to question 2.2, look at the following cell and note what each control case is doing in the `split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    ### A ###\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    ### B ###\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    ### C ###\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    ### D ###\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "- a. check for an empty split\n",
    "- b. check for max depth\n",
    "- c. process left child\n",
    "- d. process right child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Awesome! We're ready to build our tree. In the following cell, we have our `build_tree` and `print_tree` function. Most of the steps were abstracted away in `get_split` and `split` functions. Before we use the function, we can't directly use a pandas dataframe or series as input to this function.\n",
    "\n",
    "**Question 2.6** In the same cell, convert `extremes` to a numpy array and assign it to the variable `rows`. Run the cell and see the resulting tree. What do the inequalities represent? How does it relate to the data we inputted into the tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X2 < 493.979]\n",
      " [X1 < 22.750]\n",
      "  [1-5% (lowest scores)]\n",
      "  [95-100% (highest scores)]\n",
      " [X1 < 0.300]\n",
      "  [1-5% (lowest scores)]\n",
      "  [95-100% (highest scores)]\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))\n",
    "\n",
    "# YOUR CODE HERE       \n",
    "rows = extremes.values\n",
    "scratch_tree = build_tree(rows, 2, 2)\n",
    "print_tree(scratch_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Just for fun, we can also use this tree for prediction. Run the following cell to see the expected and predicted values from our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  95-100% (highest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  95-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run this cell\n",
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "for row in rows:\n",
    "    prediction = predict(scratch_tree, row)\n",
    "    print('Expected: ', row[-1])\n",
    "    print('Got: ', prediction, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a better idea of how a tree works under the hood, let's move on to scikit-learn and create a more complex tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Section 3. Implementing decision trees with scikit-learn<a name = 'sk'></a>\n",
    "\n",
    "Since our data has quite a lot features, creating and tuning a tree from scratch would be a hassle and would not necessarily lead to optimal results. Here's where scikit-learn comes in and streamlines the process for us.\n",
    "\n",
    "We'll be using scikit-learn's `DecisionTreeClassifier` ([documentation](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)) in this section, and will use a larger subset of the data to create a more complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>California County</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>Nearby City \n",
       "(to help approximate location only)</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>CES 3.0 Score</th>\n",
       "      <th>CES 3.0 Percentile</th>\n",
       "      <th>CES 3.0 Percentile Range</th>\n",
       "      <th>...</th>\n",
       "      <th>Linguistic Isolation Pctl</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Poverty Pctl</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Unemployment Pctl</th>\n",
       "      <th>Housing Burden</th>\n",
       "      <th>Housing Burden Pctl</th>\n",
       "      <th>Pop. Char.</th>\n",
       "      <th>Pop. Char. Score</th>\n",
       "      <th>Pop. Char. Pctl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6019001100</td>\n",
       "      <td>3174</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93706</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.781696</td>\n",
       "      <td>36.709695</td>\n",
       "      <td>94.090246</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>77.509665</td>\n",
       "      <td>76.3</td>\n",
       "      <td>97.121307</td>\n",
       "      <td>17.6</td>\n",
       "      <td>91.724838</td>\n",
       "      <td>26.0</td>\n",
       "      <td>79.398324</td>\n",
       "      <td>92.120494</td>\n",
       "      <td>9.553509</td>\n",
       "      <td>99.697314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6071001600</td>\n",
       "      <td>6133</td>\n",
       "      <td>San Bernardino</td>\n",
       "      <td>91761</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>-117.618013</td>\n",
       "      <td>34.057780</td>\n",
       "      <td>90.677839</td>\n",
       "      <td>99.987388</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>96.253833</td>\n",
       "      <td>72.5</td>\n",
       "      <td>94.632307</td>\n",
       "      <td>12.3</td>\n",
       "      <td>71.823836</td>\n",
       "      <td>34.1</td>\n",
       "      <td>93.754760</td>\n",
       "      <td>87.436849</td>\n",
       "      <td>9.067784</td>\n",
       "      <td>98.108210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6019000200</td>\n",
       "      <td>3167</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93706</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.805504</td>\n",
       "      <td>36.735491</td>\n",
       "      <td>85.970036</td>\n",
       "      <td>99.974776</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>78.389548</td>\n",
       "      <td>86.8</td>\n",
       "      <td>99.560025</td>\n",
       "      <td>16.1</td>\n",
       "      <td>87.980708</td>\n",
       "      <td>40.1</td>\n",
       "      <td>97.854785</td>\n",
       "      <td>94.581328</td>\n",
       "      <td>9.808714</td>\n",
       "      <td>99.987388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077000801</td>\n",
       "      <td>6692</td>\n",
       "      <td>San Joaquin</td>\n",
       "      <td>95203</td>\n",
       "      <td>Stockton</td>\n",
       "      <td>-121.314524</td>\n",
       "      <td>37.940517</td>\n",
       "      <td>82.491521</td>\n",
       "      <td>99.962164</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>75.136648</td>\n",
       "      <td>61.3</td>\n",
       "      <td>85.568825</td>\n",
       "      <td>19.6</td>\n",
       "      <td>94.973981</td>\n",
       "      <td>21.1</td>\n",
       "      <td>63.544047</td>\n",
       "      <td>86.701266</td>\n",
       "      <td>8.991499</td>\n",
       "      <td>97.717241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6019001500</td>\n",
       "      <td>2206</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93725</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.717843</td>\n",
       "      <td>36.681600</td>\n",
       "      <td>82.030814</td>\n",
       "      <td>99.949552</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>73.723504</td>\n",
       "      <td>66.4</td>\n",
       "      <td>90.232558</td>\n",
       "      <td>18.6</td>\n",
       "      <td>93.654017</td>\n",
       "      <td>28.1</td>\n",
       "      <td>83.980706</td>\n",
       "      <td>80.075199</td>\n",
       "      <td>8.304332</td>\n",
       "      <td>92.760752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Census Tract  Total Population California County    ZIP  \\\n",
       "0    6019001100              3174            Fresno  93706   \n",
       "1    6071001600              6133    San Bernardino  91761   \n",
       "2    6019000200              3167            Fresno  93706   \n",
       "3    6077000801              6692       San Joaquin  95203   \n",
       "4    6019001500              2206            Fresno  93725   \n",
       "\n",
       "  Nearby City \\n(to help approximate location only)   Longitude   Latitude  \\\n",
       "0                                            Fresno -119.781696  36.709695   \n",
       "1                                           Ontario -117.618013  34.057780   \n",
       "2                                            Fresno -119.805504  36.735491   \n",
       "3                                          Stockton -121.314524  37.940517   \n",
       "4                                            Fresno -119.717843  36.681600   \n",
       "\n",
       "   CES 3.0 Score   CES 3.0 Percentile  CES 3.0 Percentile Range  \\\n",
       "0      94.090246           100.000000  95-100% (highest scores)   \n",
       "1      90.677839            99.987388  95-100% (highest scores)   \n",
       "2      85.970036            99.974776  95-100% (highest scores)   \n",
       "3      82.491521            99.962164  95-100% (highest scores)   \n",
       "4      82.030814            99.949552  95-100% (highest scores)   \n",
       "\n",
       "        ...        Linguistic Isolation Pctl  Poverty  Poverty Pctl  \\\n",
       "0       ...                        77.509665     76.3     97.121307   \n",
       "1       ...                        96.253833     72.5     94.632307   \n",
       "2       ...                        78.389548     86.8     99.560025   \n",
       "3       ...                        75.136648     61.3     85.568825   \n",
       "4       ...                        73.723504     66.4     90.232558   \n",
       "\n",
       "   Unemployment  Unemployment Pctl  Housing Burden  Housing Burden Pctl  \\\n",
       "0          17.6          91.724838            26.0            79.398324   \n",
       "1          12.3          71.823836            34.1            93.754760   \n",
       "2          16.1          87.980708            40.1            97.854785   \n",
       "3          19.6          94.973981            21.1            63.544047   \n",
       "4          18.6          93.654017            28.1            83.980706   \n",
       "\n",
       "   Pop. Char.   Pop. Char. Score  Pop. Char. Pctl  \n",
       "0    92.120494          9.553509        99.697314  \n",
       "1    87.436849          9.067784        98.108210  \n",
       "2    94.581328          9.808714        99.987388  \n",
       "3    86.701266          8.991499        97.717241  \n",
       "4    80.075199          8.304332        92.760752  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "For our first model, we'll use the features to predict which score bracket a certain tract lies in - i.e. we want to predict the `CES 3.0 Percentile Range`. For the sake of interpretability, we'll focus on the 91st percentile and above, and the 10th percentile and below.\n",
    "\n",
    "**Question 3.1** Before we move on, what is a problem that can stem from using such a specific subset of our data to build a classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your Answer Here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look again at the scores that have been binned already in the dataset so we know how to set up our model. Run the following cell to see them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['95-100% (highest scores)', '90-95%', '85-90%', '80-85%', '75-80%',\n",
       "       '70-75%', '65-70%', '60-65%', '55-60%', '50-55%', '45-50%',\n",
       "       '40-45%', '35-40%', '30-35%', '25-30%', '20-25%', '15-20%',\n",
       "       '10-15%', '5-10%', '1-5% (lowest scores)', nan], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0['CES 3.0 Percentile Range'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have a total of four values that our tree can potentially classify if we want to take the top and bottom 10% of scores.\n",
    "\n",
    "**Question 3.2** In the cell below, create a dataframe `pct_10_90` that contains rows with percentile tract in the `96-100% (highest scores)` and `91-95%` range, as well as the `6-10%` and `1-5% (lowest scores)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>California County</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>Nearby City \n",
       "(to help approximate location only)</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>CES 3.0 Score</th>\n",
       "      <th>CES 3.0 Percentile</th>\n",
       "      <th>CES 3.0 Percentile Range</th>\n",
       "      <th>...</th>\n",
       "      <th>Linguistic Isolation Pctl</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Poverty Pctl</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Unemployment Pctl</th>\n",
       "      <th>Housing Burden</th>\n",
       "      <th>Housing Burden Pctl</th>\n",
       "      <th>Pop. Char.</th>\n",
       "      <th>Pop. Char. Score</th>\n",
       "      <th>Pop. Char. Pctl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6019001100</td>\n",
       "      <td>3174</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93706</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.781696</td>\n",
       "      <td>36.709695</td>\n",
       "      <td>94.090246</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>77.509665</td>\n",
       "      <td>76.3</td>\n",
       "      <td>97.121307</td>\n",
       "      <td>17.6</td>\n",
       "      <td>91.724838</td>\n",
       "      <td>26.0</td>\n",
       "      <td>79.398324</td>\n",
       "      <td>92.120494</td>\n",
       "      <td>9.553509</td>\n",
       "      <td>99.697314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6071001600</td>\n",
       "      <td>6133</td>\n",
       "      <td>San Bernardino</td>\n",
       "      <td>91761</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>-117.618013</td>\n",
       "      <td>34.057780</td>\n",
       "      <td>90.677839</td>\n",
       "      <td>99.987388</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>96.253833</td>\n",
       "      <td>72.5</td>\n",
       "      <td>94.632307</td>\n",
       "      <td>12.3</td>\n",
       "      <td>71.823836</td>\n",
       "      <td>34.1</td>\n",
       "      <td>93.754760</td>\n",
       "      <td>87.436849</td>\n",
       "      <td>9.067784</td>\n",
       "      <td>98.108210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6019000200</td>\n",
       "      <td>3167</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93706</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.805504</td>\n",
       "      <td>36.735491</td>\n",
       "      <td>85.970036</td>\n",
       "      <td>99.974776</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>78.389548</td>\n",
       "      <td>86.8</td>\n",
       "      <td>99.560025</td>\n",
       "      <td>16.1</td>\n",
       "      <td>87.980708</td>\n",
       "      <td>40.1</td>\n",
       "      <td>97.854785</td>\n",
       "      <td>94.581328</td>\n",
       "      <td>9.808714</td>\n",
       "      <td>99.987388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077000801</td>\n",
       "      <td>6692</td>\n",
       "      <td>San Joaquin</td>\n",
       "      <td>95203</td>\n",
       "      <td>Stockton</td>\n",
       "      <td>-121.314524</td>\n",
       "      <td>37.940517</td>\n",
       "      <td>82.491521</td>\n",
       "      <td>99.962164</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>75.136648</td>\n",
       "      <td>61.3</td>\n",
       "      <td>85.568825</td>\n",
       "      <td>19.6</td>\n",
       "      <td>94.973981</td>\n",
       "      <td>21.1</td>\n",
       "      <td>63.544047</td>\n",
       "      <td>86.701266</td>\n",
       "      <td>8.991499</td>\n",
       "      <td>97.717241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6019001500</td>\n",
       "      <td>2206</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93725</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.717843</td>\n",
       "      <td>36.681600</td>\n",
       "      <td>82.030814</td>\n",
       "      <td>99.949552</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>73.723504</td>\n",
       "      <td>66.4</td>\n",
       "      <td>90.232558</td>\n",
       "      <td>18.6</td>\n",
       "      <td>93.654017</td>\n",
       "      <td>28.1</td>\n",
       "      <td>83.980706</td>\n",
       "      <td>80.075199</td>\n",
       "      <td>8.304332</td>\n",
       "      <td>92.760752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Census Tract  Total Population California County    ZIP  \\\n",
       "0    6019001100              3174            Fresno  93706   \n",
       "1    6071001600              6133    San Bernardino  91761   \n",
       "2    6019000200              3167            Fresno  93706   \n",
       "3    6077000801              6692       San Joaquin  95203   \n",
       "4    6019001500              2206            Fresno  93725   \n",
       "\n",
       "  Nearby City \\n(to help approximate location only)   Longitude   Latitude  \\\n",
       "0                                            Fresno -119.781696  36.709695   \n",
       "1                                           Ontario -117.618013  34.057780   \n",
       "2                                            Fresno -119.805504  36.735491   \n",
       "3                                          Stockton -121.314524  37.940517   \n",
       "4                                            Fresno -119.717843  36.681600   \n",
       "\n",
       "   CES 3.0 Score   CES 3.0 Percentile  CES 3.0 Percentile Range  \\\n",
       "0      94.090246           100.000000  95-100% (highest scores)   \n",
       "1      90.677839            99.987388  95-100% (highest scores)   \n",
       "2      85.970036            99.974776  95-100% (highest scores)   \n",
       "3      82.491521            99.962164  95-100% (highest scores)   \n",
       "4      82.030814            99.949552  95-100% (highest scores)   \n",
       "\n",
       "        ...        Linguistic Isolation Pctl  Poverty  Poverty Pctl  \\\n",
       "0       ...                        77.509665     76.3     97.121307   \n",
       "1       ...                        96.253833     72.5     94.632307   \n",
       "2       ...                        78.389548     86.8     99.560025   \n",
       "3       ...                        75.136648     61.3     85.568825   \n",
       "4       ...                        73.723504     66.4     90.232558   \n",
       "\n",
       "   Unemployment  Unemployment Pctl  Housing Burden  Housing Burden Pctl  \\\n",
       "0          17.6          91.724838            26.0            79.398324   \n",
       "1          12.3          71.823836            34.1            93.754760   \n",
       "2          16.1          87.980708            40.1            97.854785   \n",
       "3          19.6          94.973981            21.1            63.544047   \n",
       "4          18.6          93.654017            28.1            83.980706   \n",
       "\n",
       "   Pop. Char.   Pop. Char. Score  Pop. Char. Pctl  \n",
       "0    92.120494          9.553509        99.697314  \n",
       "1    87.436849          9.067784        98.108210  \n",
       "2    94.581328          9.808714        99.987388  \n",
       "3    86.701266          8.991499        97.717241  \n",
       "4    80.075199          8.304332        92.760752  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "pct_10_90 = df0[(df0['CES 3.0 Percentile Range'] == '95-100% (highest scores)') \n",
    "   | (df0['CES 3.0 Percentile Range'] == '1-5% (lowest scores)')\n",
    "   | (df0['CES 3.0 Percentile Range'] == '5-10%')\n",
    "   | (df0['CES 3.0 Percentile Range'] == '90-95%')]\n",
    "\n",
    "pct_10_90.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pct_10_90['CES 3.0 Percentile Range'].unique()) == 4\n",
    "assert pct_10_90.shape == (1585,57)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our desired observations, let's filter through the certain features we want to use in our classification tree. Remember that a tree can use both continuous and categorical data, but we probably don't want to work with features like the county or zip code since it would clutter our data if we wanted to encode them. Run the following cell to drop the columns as well as the NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Population</th>\n",
       "      <th>CES 3.0 Percentile Range</th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Ozone Pctl</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM2.5 Pctl</th>\n",
       "      <th>Diesel PM</th>\n",
       "      <th>Diesel PM Pctl</th>\n",
       "      <th>Drinking Water</th>\n",
       "      <th>Drinking Water Pctl</th>\n",
       "      <th>...</th>\n",
       "      <th>Linguistic Isolation Pctl</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Poverty Pctl</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Unemployment Pctl</th>\n",
       "      <th>Housing Burden</th>\n",
       "      <th>Housing Burden Pctl</th>\n",
       "      <th>Pop. Char.</th>\n",
       "      <th>Pop. Char. Score</th>\n",
       "      <th>Pop. Char. Pctl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3174</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>0.064889</td>\n",
       "      <td>98.182950</td>\n",
       "      <td>15.40</td>\n",
       "      <td>97.218064</td>\n",
       "      <td>48.523809</td>\n",
       "      <td>95.544493</td>\n",
       "      <td>681.195604</td>\n",
       "      <td>80.915554</td>\n",
       "      <td>...</td>\n",
       "      <td>77.509665</td>\n",
       "      <td>76.3</td>\n",
       "      <td>97.121307</td>\n",
       "      <td>17.6</td>\n",
       "      <td>91.724838</td>\n",
       "      <td>26.0</td>\n",
       "      <td>79.398324</td>\n",
       "      <td>92.120494</td>\n",
       "      <td>9.553509</td>\n",
       "      <td>99.697314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6133</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>0.062163</td>\n",
       "      <td>91.101431</td>\n",
       "      <td>13.31</td>\n",
       "      <td>93.637725</td>\n",
       "      <td>38.556339</td>\n",
       "      <td>92.121966</td>\n",
       "      <td>904.657603</td>\n",
       "      <td>96.108270</td>\n",
       "      <td>...</td>\n",
       "      <td>96.253833</td>\n",
       "      <td>72.5</td>\n",
       "      <td>94.632307</td>\n",
       "      <td>12.3</td>\n",
       "      <td>71.823836</td>\n",
       "      <td>34.1</td>\n",
       "      <td>93.754760</td>\n",
       "      <td>87.436849</td>\n",
       "      <td>9.067784</td>\n",
       "      <td>98.108210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3167</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>0.062163</td>\n",
       "      <td>91.101431</td>\n",
       "      <td>15.40</td>\n",
       "      <td>97.218064</td>\n",
       "      <td>47.445208</td>\n",
       "      <td>95.420037</td>\n",
       "      <td>681.195604</td>\n",
       "      <td>80.915554</td>\n",
       "      <td>...</td>\n",
       "      <td>78.389548</td>\n",
       "      <td>86.8</td>\n",
       "      <td>99.560025</td>\n",
       "      <td>16.1</td>\n",
       "      <td>87.980708</td>\n",
       "      <td>40.1</td>\n",
       "      <td>97.854785</td>\n",
       "      <td>94.581328</td>\n",
       "      <td>9.808714</td>\n",
       "      <td>99.987388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>0.046178</td>\n",
       "      <td>53.018046</td>\n",
       "      <td>12.54</td>\n",
       "      <td>84.019461</td>\n",
       "      <td>24.117036</td>\n",
       "      <td>73.515868</td>\n",
       "      <td>278.756235</td>\n",
       "      <td>29.113135</td>\n",
       "      <td>...</td>\n",
       "      <td>75.136648</td>\n",
       "      <td>61.3</td>\n",
       "      <td>85.568825</td>\n",
       "      <td>19.6</td>\n",
       "      <td>94.973981</td>\n",
       "      <td>21.1</td>\n",
       "      <td>63.544047</td>\n",
       "      <td>86.701266</td>\n",
       "      <td>8.991499</td>\n",
       "      <td>97.717241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2206</td>\n",
       "      <td>95-100% (highest scores)</td>\n",
       "      <td>0.064889</td>\n",
       "      <td>98.182950</td>\n",
       "      <td>15.40</td>\n",
       "      <td>97.218064</td>\n",
       "      <td>18.845944</td>\n",
       "      <td>58.220286</td>\n",
       "      <td>1000.240794</td>\n",
       "      <td>98.640389</td>\n",
       "      <td>...</td>\n",
       "      <td>73.723504</td>\n",
       "      <td>66.4</td>\n",
       "      <td>90.232558</td>\n",
       "      <td>18.6</td>\n",
       "      <td>93.654017</td>\n",
       "      <td>28.1</td>\n",
       "      <td>83.980706</td>\n",
       "      <td>80.075199</td>\n",
       "      <td>8.304332</td>\n",
       "      <td>92.760752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Population  CES 3.0 Percentile Range     Ozone  Ozone Pctl  PM2.5  \\\n",
       "0              3174  95-100% (highest scores)  0.064889   98.182950  15.40   \n",
       "1              6133  95-100% (highest scores)  0.062163   91.101431  13.31   \n",
       "2              3167  95-100% (highest scores)  0.062163   91.101431  15.40   \n",
       "3              6692  95-100% (highest scores)  0.046178   53.018046  12.54   \n",
       "4              2206  95-100% (highest scores)  0.064889   98.182950  15.40   \n",
       "\n",
       "   PM2.5 Pctl  Diesel PM  Diesel PM Pctl  Drinking Water  Drinking Water Pctl  \\\n",
       "0   97.218064  48.523809       95.544493      681.195604            80.915554   \n",
       "1   93.637725  38.556339       92.121966      904.657603            96.108270   \n",
       "2   97.218064  47.445208       95.420037      681.195604            80.915554   \n",
       "3   84.019461  24.117036       73.515868      278.756235            29.113135   \n",
       "4   97.218064  18.845944       58.220286     1000.240794            98.640389   \n",
       "\n",
       "        ...         Linguistic Isolation Pctl  Poverty  Poverty Pctl  \\\n",
       "0       ...                         77.509665     76.3     97.121307   \n",
       "1       ...                         96.253833     72.5     94.632307   \n",
       "2       ...                         78.389548     86.8     99.560025   \n",
       "3       ...                         75.136648     61.3     85.568825   \n",
       "4       ...                         73.723504     66.4     90.232558   \n",
       "\n",
       "   Unemployment  Unemployment Pctl  Housing Burden  Housing Burden Pctl  \\\n",
       "0          17.6          91.724838            26.0            79.398324   \n",
       "1          12.3          71.823836            34.1            93.754760   \n",
       "2          16.1          87.980708            40.1            97.854785   \n",
       "3          19.6          94.973981            21.1            63.544047   \n",
       "4          18.6          93.654017            28.1            83.980706   \n",
       "\n",
       "   Pop. Char.   Pop. Char. Score  Pop. Char. Pctl  \n",
       "0    92.120494          9.553509        99.697314  \n",
       "1    87.436849          9.067784        98.108210  \n",
       "2    94.581328          9.808714        99.987388  \n",
       "3    86.701266          8.991499        97.717241  \n",
       "4    80.075199          8.304332        92.760752  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_10_90 = pct_10_90.drop(columns = ['Census Tract', 'CES 3.0 Score', ' CES 3.0 Percentile', \n",
    "                                      'California County', 'ZIP', 'Nearby City \\n(to help approximate location only)', \n",
    "                                      'Longitude', 'Latitude', 'SB 535 Disadvantaged Community'])\n",
    "pct_10_90 = pct_10_90.dropna()\n",
    "pct_10_90.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need to do before we create our decision tree is to drop the `Pctl` columns, as well as create the testing, training, and validation sets.\n",
    "\n",
    "**Question 3.3** Create a dataframe `features` that contain our predictors. Drop all columns that contain the string `Pctl` for our set of features. Don't forget to drop the percentile range column. We don't want that in our features! \n",
    "\n",
    "Then, assign the percentile ranges to the variable `target`.\n",
    "\n",
    "Lastly, create the training, testing, and validation sets by splitting the set into training and testing first, then split the training test into training and validation. Use `random_state = 1` both times, and create an 80/20 train/test split, and a 75/25 train/validation split.\n",
    "\n",
    "*Note:* Here, `X_train` and `y_train` refer to the training set, while `X_val` and `y_val` are the validation set, and `X_test` and `y_test` are the test sets. `X` and `y` contain the training *and* validation sets, but they're just an intermediate variable in the code below. Throughout the lab, we'll be training models on `X_train` and `y_train` and using `X_val` and `y_val` to tune their parameters. Then, at the very very end, we'll look at how each model performs on `X_test` and `y_test`. Because we'll be doing cross-validation in some but not all cases, we're reserving the 'validation' data set now that will be used for benchmarking as we go along.  But in practice it's acting like a static test data set; the error reported from the validation data set is different from cross-validated error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION \n",
    "drop_columns = [i for i in pct_10_90.columns if 'Pctl' in i]\n",
    "drop_columns.append('CES 3.0 Percentile Range')\n",
    "\n",
    "features = pct_10_90.drop(columns=drop_columns)\n",
    "target = pct_10_90['CES 3.0 Percentile Range']\n",
    "\n",
    "# split test set\n",
    "X, X_test, y, y_test = train_test_split(features, target, random_state = 1, test_size = .2)\n",
    "\n",
    "# split between train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state = 1, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert features.shape[1] == X_test.shape[1] == 25\n",
    "assert X_val.shape[0] == y_val.shape[0] == 299"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We can finally create a tree! \n",
    "\n",
    "**Question 3.4** Instantiate a `DecisionTreeClassifer` model and call it `first_tree`. Fit the model using the training data, and score it using both the training and validation set. Assign the scores to the variables `train_score` and `val_score` respectively. \n",
    "\n",
    "Remember: the general syntax for all scikit-learn models is the same, so if you're not sure where to start, take a look at the documentation for `DecisionTreeClassifier` as well as previous assignments that use scikit-learn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 25\n",
      "Number of nodes (internal and terminal): 109 \n",
      "\n",
      "Train Score:  1.0\n",
      "Validation Score:  0.9297658862876255\n"
     ]
    }
   ],
   "source": [
    "#SOLUTION\n",
    "first_tree = DecisionTreeClassifier()\n",
    "first_tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Number of features: {}\".format(first_tree.tree_.n_features))\n",
    "print(\"Number of nodes (internal and terminal): {}\".format(first_tree.tree_.node_count), \"\\n\")\n",
    "\n",
    "train_score = first_tree.score(X_train, y_train)\n",
    "val_score = first_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', train_score)\n",
    "print('Validation Score: ', val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score isn't too shabby for a tree that was put together pretty quickly. The nice part about decision trees is that they're easy to visualize and interpret and with scikit-learn, we can export the an image of the tree. Unfortunately, due limitations on DataHub, we can't output an image directly in a notebook. \n",
    "\n",
    "Luckily, we can copy the code and visualize the tree on [Webgraphviz](http://webgraphviz.com). By running the following cell, you'll see a pretty long output -- follow the link and copy and paste the output to get a visualization of the decision tree we fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph Tree {\n",
      "node [shape=box] ;\n",
      "0 [label=\"Pop. Char. Score <= 5.396\\ngini = 0.749\\nsamples = 896\\nvalue = [220, 206, 237, 233]\"] ;\n",
      "1 [label=\"Pop. Char. Score <= 1.545\\ngini = 0.499\\nsamples = 426\\nvalue = [220, 206, 0, 0]\"] ;\n",
      "0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\n",
      "2 [label=\"Pollution Burden <= 37.23\\ngini = 0.247\\nsamples = 166\\nvalue = [142, 24, 0, 0]\"] ;\n",
      "1 -> 2 ;\n",
      "3 [label=\"Cardiovascular Disease <= 2.28\\ngini = 0.033\\nsamples = 119\\nvalue = [117, 2, 0, 0]\"] ;\n",
      "2 -> 3 ;\n",
      "4 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0]\"] ;\n",
      "3 -> 4 ;\n",
      "5 [label=\"Pollution Burden <= 36.201\\ngini = 0.017\\nsamples = 118\\nvalue = [117, 1, 0, 0]\"] ;\n",
      "3 -> 5 ;\n",
      "6 [label=\"gini = 0.0\\nsamples = 109\\nvalue = [109, 0, 0, 0]\"] ;\n",
      "5 -> 6 ;\n",
      "7 [label=\"Linguistic Isolation <= 2.85\\ngini = 0.198\\nsamples = 9\\nvalue = [8, 1, 0, 0]\"] ;\n",
      "5 -> 7 ;\n",
      "8 [label=\"gini = 0.0\\nsamples = 8\\nvalue = [8, 0, 0, 0]\"] ;\n",
      "7 -> 8 ;\n",
      "9 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0]\"] ;\n",
      "7 -> 9 ;\n",
      "10 [label=\"Pop. Char.  <= 10.559\\ngini = 0.498\\nsamples = 47\\nvalue = [25, 22, 0, 0]\"] ;\n",
      "2 -> 10 ;\n",
      "11 [label=\"Pollution Burden <= 55.226\\ngini = 0.08\\nsamples = 24\\nvalue = [23, 1, 0, 0]\"] ;\n",
      "10 -> 11 ;\n",
      "12 [label=\"gini = 0.0\\nsamples = 23\\nvalue = [23, 0, 0, 0]\"] ;\n",
      "11 -> 12 ;\n",
      "13 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0]\"] ;\n",
      "11 -> 13 ;\n",
      "14 [label=\"Linguistic Isolation <= 5.8\\ngini = 0.159\\nsamples = 23\\nvalue = [2, 21, 0, 0]\"] ;\n",
      "10 -> 14 ;\n",
      "15 [label=\"Pop. Char.  <= 11.123\\ngini = 0.087\\nsamples = 22\\nvalue = [1, 21, 0, 0]\"] ;\n",
      "14 -> 15 ;\n",
      "16 [label=\"Pollution Burden <= 48.181\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1, 0, 0]\"] ;\n",
      "15 -> 16 ;\n",
      "17 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0]\"] ;\n",
      "16 -> 17 ;\n",
      "18 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0]\"] ;\n",
      "16 -> 18 ;\n",
      "19 [label=\"gini = 0.0\\nsamples = 20\\nvalue = [0, 20, 0, 0]\"] ;\n",
      "15 -> 19 ;\n",
      "20 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0]\"] ;\n",
      "14 -> 20 ;\n",
      "21 [label=\"Pollution Burden <= 26.734\\ngini = 0.42\\nsamples = 260\\nvalue = [78, 182, 0, 0]\"] ;\n",
      "1 -> 21 ;\n",
      "22 [label=\"Pop. Char.  <= 20.148\\ngini = 0.5\\nsamples = 140\\nvalue = [69, 71, 0, 0]\"] ;\n",
      "21 -> 22 ;\n",
      "23 [label=\"Drinking Water <= 605.636\\ngini = 0.041\\nsamples = 48\\nvalue = [47, 1, 0, 0]\"] ;\n",
      "22 -> 23 ;\n",
      "24 [label=\"gini = 0.0\\nsamples = 44\\nvalue = [44, 0, 0, 0]\"] ;\n",
      "23 -> 24 ;\n",
      "25 [label=\"PM2.5 <= 9.953\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 1, 0, 0]\"] ;\n",
      "23 -> 25 ;\n",
      "26 [label=\"gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0, 0]\"] ;\n",
      "25 -> 26 ;\n",
      "27 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0]\"] ;\n",
      "25 -> 27 ;\n",
      "28 [label=\"Pollution Burden <= 16.894\\ngini = 0.364\\nsamples = 92\\nvalue = [22, 70, 0, 0]\"] ;\n",
      "22 -> 28 ;\n",
      "29 [label=\"Pop. Char. Score <= 3.726\\ngini = 0.375\\nsamples = 16\\nvalue = [12, 4, 0, 0]\"] ;\n",
      "28 -> 29 ;\n",
      "30 [label=\"gini = 0.0\\nsamples = 11\\nvalue = [11, 0, 0, 0]\"] ;\n",
      "29 -> 30 ;\n",
      "31 [label=\"Haz. Waste <= 0.005\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 4, 0, 0]\"] ;\n",
      "29 -> 31 ;\n",
      "32 [label=\"gini = 0.0\\nsamples = 4\\nvalue = [0, 4, 0, 0]\"] ;\n",
      "31 -> 32 ;\n",
      "33 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0]\"] ;\n",
      "31 -> 33 ;\n",
      "34 [label=\"Pop. Char.  <= 23.939\\ngini = 0.229\\nsamples = 76\\nvalue = [10, 66, 0, 0]\"] ;\n",
      "28 -> 34 ;\n",
      "35 [label=\"Pollution Burden <= 22.078\\ngini = 0.476\\nsamples = 23\\nvalue = [9, 14, 0, 0]\"] ;\n",
      "34 -> 35 ;\n",
      "36 [label=\"Poverty <= 20.25\\ngini = 0.198\\nsamples = 9\\nvalue = [8, 1, 0, 0]\"] ;\n",
      "35 -> 36 ;\n",
      "37 [label=\"gini = 0.0\\nsamples = 7\\nvalue = [7, 0, 0, 0]\"] ;\n",
      "36 -> 37 ;\n",
      "38 [label=\"Education <= 3.25\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1, 0, 0]\"] ;\n",
      "36 -> 38 ;\n",
      "39 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0]\"] ;\n",
      "38 -> 39 ;\n",
      "40 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0]\"] ;\n",
      "38 -> 40 ;\n",
      "41 [label=\"Total Population <= 5456.0\\ngini = 0.133\\nsamples = 14\\nvalue = [1, 13, 0, 0]\"] ;\n",
      "35 -> 41 ;\n",
      "42 [label=\"gini = 0.0\\nsamples = 13\\nvalue = [0, 13, 0, 0]\"] ;\n",
      "41 -> 42 ;\n",
      "43 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0]\"] ;\n",
      "41 -> 43 ;\n",
      "44 [label=\"Cardiovascular Disease <= 4.18\\ngini = 0.037\\nsamples = 53\\nvalue = [1, 52, 0, 0]\"] ;\n",
      "34 -> 44 ;\n",
      "45 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0]\"] ;\n",
      "44 -> 45 ;\n",
      "46 [label=\"gini = 0.0\\nsamples = 52\\nvalue = [0, 52, 0, 0]\"] ;\n",
      "44 -> 46 ;\n",
      "47 [label=\"Pop. Char. Score <= 1.7\\ngini = 0.139\\nsamples = 120\\nvalue = [9, 111, 0, 0]\"] ;\n",
      "21 -> 47 ;\n",
      "48 [label=\"Pollution Burden <= 32.16\\ngini = 0.408\\nsamples = 28\\nvalue = [8, 20, 0, 0]\"] ;\n",
      "47 -> 48 ;\n",
      "49 [label=\"Education <= 6.6\\ngini = 0.198\\nsamples = 9\\nvalue = [8, 1, 0, 0]\"] ;\n",
      "48 -> 49 ;\n",
      "50 [label=\"gini = 0.0\\nsamples = 8\\nvalue = [8, 0, 0, 0]\"] ;\n",
      "49 -> 50 ;\n",
      "51 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0]\"] ;\n",
      "49 -> 51 ;\n",
      "52 [label=\"gini = 0.0\\nsamples = 19\\nvalue = [0, 19, 0, 0]\"] ;\n",
      "48 -> 52 ;\n",
      "53 [label=\"Housing Burden <= 20.45\\ngini = 0.022\\nsamples = 92\\nvalue = [1, 91, 0, 0]\"] ;\n",
      "47 -> 53 ;\n",
      "54 [label=\"gini = 0.0\\nsamples = 91\\nvalue = [0, 91, 0, 0]\"] ;\n",
      "53 -> 54 ;\n",
      "55 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0]\"] ;\n",
      "53 -> 55 ;\n",
      "56 [label=\"Pollution Burden <= 58.055\\ngini = 0.5\\nsamples = 470\\nvalue = [0, 0, 237, 233]\"] ;\n",
      "0 -> 56 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\n",
      "57 [label=\"Pop. Char. Score <= 9.154\\ngini = 0.363\\nsamples = 193\\nvalue = [0, 0, 147, 46]\"] ;\n",
      "56 -> 57 ;\n",
      "58 [label=\"Pop. Char.  <= 79.274\\ngini = 0.262\\nsamples = 161\\nvalue = [0, 0, 136, 25]\"] ;\n",
      "57 -> 58 ;\n",
      "59 [label=\"Housing Burden <= 16.75\\ngini = 0.027\\nsamples = 73\\nvalue = [0, 0, 72, 1]\"] ;\n",
      "58 -> 59 ;\n",
      "60 [label=\"Pop. Char. Score <= 8.048\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 3, 1]\"] ;\n",
      "59 -> 60 ;\n",
      "61 [label=\"gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0]\"] ;\n",
      "60 -> 61 ;\n",
      "62 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1]\"] ;\n",
      "60 -> 62 ;\n",
      "63 [label=\"gini = 0.0\\nsamples = 69\\nvalue = [0, 0, 69, 0]\"] ;\n",
      "59 -> 63 ;\n",
      "64 [label=\"Pollution Burden <= 54.442\\ngini = 0.397\\nsamples = 88\\nvalue = [0, 0, 64, 24]\"] ;\n",
      "58 -> 64 ;\n",
      "65 [label=\"Pollution Burden <= 52.203\\ngini = 0.163\\nsamples = 67\\nvalue = [0, 0, 61, 6]\"] ;\n",
      "64 -> 65 ;\n",
      "66 [label=\"gini = 0.0\\nsamples = 46\\nvalue = [0, 0, 46, 0]\"] ;\n",
      "65 -> 66 ;\n",
      "67 [label=\"Pop. Char.  <= 84.334\\ngini = 0.408\\nsamples = 21\\nvalue = [0, 0, 15, 6]\"] ;\n",
      "65 -> 67 ;\n",
      "68 [label=\"gini = 0.0\\nsamples = 15\\nvalue = [0, 0, 15, 0]\"] ;\n",
      "67 -> 68 ;\n",
      "69 [label=\"gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 0, 6]\"] ;\n",
      "67 -> 69 ;\n",
      "70 [label=\"Pop. Char.  <= 80.403\\ngini = 0.245\\nsamples = 21\\nvalue = [0, 0, 3, 18]\"] ;\n",
      "64 -> 70 ;\n",
      "71 [label=\"Pollution Burden Score <= 6.959\\ngini = 0.49\\nsamples = 7\\nvalue = [0, 0, 3, 4]\"] ;\n",
      "70 -> 71 ;\n",
      "72 [label=\"Total Population <= 4020.5\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 3, 1]\"] ;\n",
      "71 -> 72 ;\n",
      "73 [label=\"gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0]\"] ;\n",
      "72 -> 73 ;\n",
      "74 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1]\"] ;\n",
      "72 -> 74 ;\n",
      "75 [label=\"gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 3]\"] ;\n",
      "71 -> 75 ;\n",
      "76 [label=\"gini = 0.0\\nsamples = 14\\nvalue = [0, 0, 0, 14]\"] ;\n",
      "70 -> 76 ;\n",
      "77 [label=\"Pollution Burden Score <= 6.15\\ngini = 0.451\\nsamples = 32\\nvalue = [0, 0, 11, 21]\"] ;\n",
      "57 -> 77 ;\n",
      "78 [label=\"gini = 0.0\\nsamples = 11\\nvalue = [0, 0, 11, 0]\"] ;\n",
      "77 -> 78 ;\n",
      "79 [label=\"gini = 0.0\\nsamples = 21\\nvalue = [0, 0, 0, 21]\"] ;\n",
      "77 -> 79 ;\n",
      "80 [label=\"Pop. Char. Score <= 7.665\\ngini = 0.439\\nsamples = 277\\nvalue = [0, 0, 90, 187]\"] ;\n",
      "56 -> 80 ;\n",
      "81 [label=\"Pollution Burden <= 66.918\\ngini = 0.476\\nsamples = 133\\nvalue = [0, 0, 81, 52]\"] ;\n",
      "80 -> 81 ;\n",
      "82 [label=\"Pop. Char.  <= 69.764\\ngini = 0.269\\nsamples = 75\\nvalue = [0, 0, 63, 12]\"] ;\n",
      "81 -> 82 ;\n",
      "83 [label=\"gini = 0.0\\nsamples = 37\\nvalue = [0, 0, 37, 0]\"] ;\n",
      "82 -> 83 ;\n",
      "84 [label=\"Pollution Burden Score <= 7.699\\ngini = 0.432\\nsamples = 38\\nvalue = [0, 0, 26, 12]\"] ;\n",
      "82 -> 84 ;\n",
      "85 [label=\"Total Population <= 6393.5\\ngini = 0.185\\nsamples = 29\\nvalue = [0, 0, 26, 3]\"] ;\n",
      "84 -> 85 ;\n",
      "86 [label=\"gini = 0.0\\nsamples = 25\\nvalue = [0, 0, 25, 0]\"] ;\n",
      "85 -> 86 ;\n",
      "87 [label=\"Housing Burden <= 19.25\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 1, 3]\"] ;\n",
      "85 -> 87 ;\n",
      "88 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0]\"] ;\n",
      "87 -> 88 ;\n",
      "89 [label=\"gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 3]\"] ;\n",
      "87 -> 89 ;\n",
      "90 [label=\"gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 0, 9]\"] ;\n",
      "84 -> 90 ;\n",
      "91 [label=\"Pop. Char.  <= 63.274\\ngini = 0.428\\nsamples = 58\\nvalue = [0, 0, 18, 40]\"] ;\n",
      "81 -> 91 ;\n",
      "92 [label=\"Cleanup Sites <= 77.225\\ngini = 0.117\\nsamples = 16\\nvalue = [0, 0, 15, 1]\"] ;\n",
      "91 -> 92 ;\n",
      "93 [label=\"gini = 0.0\\nsamples = 14\\nvalue = [0, 0, 14, 0]\"] ;\n",
      "92 -> 93 ;\n",
      "94 [label=\"Pollution Burden <= 76.801\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 1, 1]\"] ;\n",
      "92 -> 94 ;\n",
      "95 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1]\"] ;\n",
      "94 -> 95 ;\n",
      "96 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0]\"] ;\n",
      "94 -> 96 ;\n",
      "97 [label=\"Pop. Char. Score <= 6.8\\ngini = 0.133\\nsamples = 42\\nvalue = [0, 0, 3, 39]\"] ;\n",
      "91 -> 97 ;\n",
      "98 [label=\"Poverty <= 40.55\\ngini = 0.49\\nsamples = 7\\nvalue = [0, 0, 3, 4]\"] ;\n",
      "97 -> 98 ;\n",
      "99 [label=\"gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 0, 4]\"] ;\n",
      "98 -> 99 ;\n",
      "100 [label=\"gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0]\"] ;\n",
      "98 -> 100 ;\n",
      "101 [label=\"gini = 0.0\\nsamples = 35\\nvalue = [0, 0, 0, 35]\"] ;\n",
      "97 -> 101 ;\n",
      "102 [label=\"Pollution Burden Score <= 7.41\\ngini = 0.117\\nsamples = 144\\nvalue = [0, 0, 9, 135]\"] ;\n",
      "80 -> 102 ;\n",
      "103 [label=\"Pop. Char. Score <= 7.916\\ngini = 0.315\\nsamples = 46\\nvalue = [0, 0, 9, 37]\"] ;\n",
      "102 -> 103 ;\n",
      "104 [label=\"gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8, 0]\"] ;\n",
      "103 -> 104 ;\n",
      "105 [label=\"Total Population <= 2408.0\\ngini = 0.051\\nsamples = 38\\nvalue = [0, 0, 1, 37]\"] ;\n",
      "103 -> 105 ;\n",
      "106 [label=\"gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0]\"] ;\n",
      "105 -> 106 ;\n",
      "107 [label=\"gini = 0.0\\nsamples = 37\\nvalue = [0, 0, 0, 37]\"] ;\n",
      "105 -> 107 ;\n",
      "108 [label=\"gini = 0.0\\nsamples = 98\\nvalue = [0, 0, 0, 98]\"] ;\n",
      "102 -> 108 ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "print(tree.export_graphviz(first_tree, feature_names=X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5** What does each line in a given box in the Webgraphviz visualization represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR ANSWER HERE*** <br>\n",
    "First line:\n",
    "\n",
    "Second line:\n",
    "\n",
    "Third line:\n",
    "\n",
    "Fourth Line:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6** Based on the visualization:\n",
    "1. What are the problems or pitfalls with the model we just created? \n",
    "1. Can you infer the \"most\" and \"least\" important features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "With scikit-learn, we're also able to check the feature importance. Running the following cell, we can see the features and the their importance based on the data we used to fit the tree -- this can be helpful when tuning or pruning the tree! The feature importance is a measure of how much of a decrease in the Gini index results from including that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total Population</td>\n",
       "      <td>0.013680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ozone</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PM2.5</td>\n",
       "      <td>0.002234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diesel PM</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drinking Water</td>\n",
       "      <td>0.000683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pesticides</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tox. Release</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Traffic</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cleanup Sites</td>\n",
       "      <td>0.001303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Groundwater Threats</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Haz. Waste</td>\n",
       "      <td>0.002383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Imp. Water Bodies</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Solid Waste</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pollution Burden</td>\n",
       "      <td>0.224076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pollution Burden Score</td>\n",
       "      <td>0.044396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Asthma</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Low Birth Weight</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cardiovascular Disease</td>\n",
       "      <td>0.005827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Education</td>\n",
       "      <td>0.004138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Linguistic Isolation</td>\n",
       "      <td>0.005245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Poverty</td>\n",
       "      <td>0.006266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Unemployment</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Housing Burden</td>\n",
       "      <td>0.005885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pop. Char.</td>\n",
       "      <td>0.140768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pop. Char. Score</td>\n",
       "      <td>0.543117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature  Importance\n",
       "0         Total Population    0.013680\n",
       "1                    Ozone    0.000000\n",
       "2                    PM2.5    0.002234\n",
       "3                Diesel PM    0.000000\n",
       "4           Drinking Water    0.000683\n",
       "5               Pesticides    0.000000\n",
       "6             Tox. Release    0.000000\n",
       "7                  Traffic    0.000000\n",
       "8            Cleanup Sites    0.001303\n",
       "9      Groundwater Threats    0.000000\n",
       "10              Haz. Waste    0.002383\n",
       "11       Imp. Water Bodies    0.000000\n",
       "12             Solid Waste    0.000000\n",
       "13        Pollution Burden    0.224076\n",
       "14  Pollution Burden Score    0.044396\n",
       "15                  Asthma    0.000000\n",
       "16        Low Birth Weight    0.000000\n",
       "17  Cardiovascular Disease    0.005827\n",
       "18               Education    0.004138\n",
       "19    Linguistic Isolation    0.005245\n",
       "20                 Poverty    0.006266\n",
       "21            Unemployment    0.000000\n",
       "22          Housing Burden    0.005885\n",
       "23             Pop. Char.     0.140768\n",
       "24        Pop. Char. Score    0.543117"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Feature': X.columns, 'Importance': first_tree.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "We've had a good look at what we can do with a decision tree in using scikit-learn. Let's dive into learning about the hyperparameters, which can help improve our classification model. Again, the documentation for `DecisionTreeClassifier` is linked [here](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
    "\n",
    "If you noticed in the tree earlier, there were a *lot* of nodes. Some of these nodes have a gini score of 0 or have small sample numbers. We can overcome these problems by tweaking the hyperparameters of the tree. \n",
    "\n",
    "**Quesiton 3.7** In the following cell, we have almost the exact same code from earlier, but we've added two parameters: `max_leaf_nodes` and `max_features`. Try two or three sets of different values for these two parameters and see if we can improve our original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 25\n",
      "Number of nodes (leaves): 9 \n",
      "\n",
      "Train Score:  0.7667410714285714\n",
      "Validation Score:  0.7391304347826086\n"
     ]
    }
   ],
   "source": [
    "# possible solution\n",
    "tuned_tree = DecisionTreeClassifier(max_leaf_nodes=5, max_features=25)\n",
    "tuned_tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Number of features: {}\".format(tuned_tree.tree_.n_features))\n",
    "print(\"Number of nodes (leaves): {}\".format(tuned_tree.tree_.node_count),\"\\n\")\n",
    "\n",
    "tuned_train_score = tuned_tree.score(X_train, y_train)\n",
    "tuned_val_score = tuned_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', tuned_train_score)\n",
    "print('Validation Score: ', tuned_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Were you able to obtain validation score higher than what we had originally (it's ok if you didn't!)? It probably took some time to figure out which values were better than others.\n",
    "\n",
    "Fortunately, we don't have to test various parameters by manually inputting them and running the cell, which would be exhausting! Instead, we can use [`RandomizedSearchCV` from scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) to help us find optimal parameters. \n",
    "\n",
    "It takes in a model, a distribution of parameters we want to test in the model, and other parameters that we can tweak. We'll only use `cv` and `n_iter` along with the two required arguments. \n",
    "\n",
    "The parameter distribution is a dictionary that takes in the parameter name as a key and a range of random values that we want to test. We'll be using `randint` from scipy.stats. Run the following cell -- we will also fit the CV search which will take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/app/venv/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n",
       "                   estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features=25,\n",
       "                                                    max_leaf_nodes=5,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    presort=False,\n",
       "                                                    random_state=None,\n",
       "                                                    splitter='best'),\n",
       "                   iid='warn'...\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa454958f60>,\n",
       "                                        'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa454958da0>,\n",
       "                                        'max_leaf_nodes': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa454958748>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=2, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {'max_leaf_nodes': randint(3, 100),\n",
    "              'max_features': randint(2, 25),\n",
    "              'max_depth': randint(1, 10)}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(tuned_tree, param_distributions=param_dist, \n",
    "                                cv=10, n_iter=200, random_state = 2)\n",
    "rnd_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting our data, we can check the score and the values for the parameters that return the \"best\" score. Run the following cell to get these values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9017857142857143\n",
      "{'max_depth': 8, 'max_features': 22, 'max_leaf_nodes': 28}\n"
     ]
    }
   ],
   "source": [
    "print(rnd_search.best_score_) # This is cross validation error from the training data set.\n",
    "print(rnd_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8** With our new parameters, set the parameters of `tuned_tree` to the 3 parameters that we found using the randomized search. Then, score the model using the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9754464285714286\n",
      "Validation Score:  0.939799331103679\n"
     ]
    }
   ],
   "source": [
    "#SOLUTION\n",
    "tuned_tree.set_params(max_features=20, max_leaf_nodes=29, max_depth = 7)\n",
    "tuned_tree.fit(X_train, y_train)\n",
    "\n",
    "tuned_train_score = tuned_tree.score(X_train, y_train)\n",
    "tuned_val_score = tuned_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', tuned_train_score)\n",
    "print('Validation Score: ', tuned_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Hopefully this tuned tree performed better than our original one (due to the random samples, it's hard to say). Let's also print out the feature scores like we did initially. Do you see a difference between the feature importances of the tuned tree compared to those of the first tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total Population</td>\n",
       "      <td>0.006128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ozone</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PM2.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diesel PM</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drinking Water</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pesticides</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tox. Release</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Traffic</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cleanup Sites</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Groundwater Threats</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Haz. Waste</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Imp. Water Bodies</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Solid Waste</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pollution Burden</td>\n",
       "      <td>0.077838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pollution Burden Score</td>\n",
       "      <td>0.197310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Asthma</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Low Birth Weight</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cardiovascular Disease</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Education</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Linguistic Isolation</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Poverty</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Unemployment</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Housing Burden</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pop. Char.</td>\n",
       "      <td>0.150583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pop. Char. Score</td>\n",
       "      <td>0.568142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature  Importance\n",
       "0         Total Population    0.006128\n",
       "1                    Ozone    0.000000\n",
       "2                    PM2.5    0.000000\n",
       "3                Diesel PM    0.000000\n",
       "4           Drinking Water    0.000000\n",
       "5               Pesticides    0.000000\n",
       "6             Tox. Release    0.000000\n",
       "7                  Traffic    0.000000\n",
       "8            Cleanup Sites    0.000000\n",
       "9      Groundwater Threats    0.000000\n",
       "10              Haz. Waste    0.000000\n",
       "11       Imp. Water Bodies    0.000000\n",
       "12             Solid Waste    0.000000\n",
       "13        Pollution Burden    0.077838\n",
       "14  Pollution Burden Score    0.197310\n",
       "15                  Asthma    0.000000\n",
       "16        Low Birth Weight    0.000000\n",
       "17  Cardiovascular Disease    0.000000\n",
       "18               Education    0.000000\n",
       "19    Linguistic Isolation    0.000000\n",
       "20                 Poverty    0.000000\n",
       "21            Unemployment    0.000000\n",
       "22          Housing Burden    0.000000\n",
       "23             Pop. Char.     0.150583\n",
       "24        Pop. Char. Score    0.568142"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Feature':X_train.columns, 'Importance': tuned_tree.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, for this tuned tree, let's take a look at how adjusting the hyperparameters altered the decision tree. Like last time, copy and paste the code into [Webgraphviz](http://webgraphviz.com) to visualize the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph Tree {\n",
      "node [shape=box] ;\n",
      "0 [label=\"Pop. Char. Score <= 5.396\\ngini = 0.749\\nsamples = 896\\nvalue = [220, 206, 237, 233]\"] ;\n",
      "1 [label=\"Pop. Char. Score <= 1.545\\ngini = 0.499\\nsamples = 426\\nvalue = [220, 206, 0, 0]\"] ;\n",
      "0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\n",
      "3 [label=\"Pollution Burden <= 37.23\\ngini = 0.247\\nsamples = 166\\nvalue = [142, 24, 0, 0]\"] ;\n",
      "1 -> 3 ;\n",
      "17 [label=\"gini = 0.033\\nsamples = 119\\nvalue = [117, 2, 0, 0]\"] ;\n",
      "3 -> 17 ;\n",
      "18 [label=\"Pop. Char. Score <= 1.095\\ngini = 0.498\\nsamples = 47\\nvalue = [25, 22, 0, 0]\"] ;\n",
      "3 -> 18 ;\n",
      "19 [label=\"gini = 0.08\\nsamples = 24\\nvalue = [23, 1, 0, 0]\"] ;\n",
      "18 -> 19 ;\n",
      "20 [label=\"gini = 0.159\\nsamples = 23\\nvalue = [2, 21, 0, 0]\"] ;\n",
      "18 -> 20 ;\n",
      "4 [label=\"Pollution Burden Score <= 3.293\\ngini = 0.42\\nsamples = 260\\nvalue = [78, 182, 0, 0]\"] ;\n",
      "1 -> 4 ;\n",
      "9 [label=\"Pop. Char. Score <= 2.089\\ngini = 0.5\\nsamples = 140\\nvalue = [69, 71, 0, 0]\"] ;\n",
      "4 -> 9 ;\n",
      "11 [label=\"gini = 0.041\\nsamples = 48\\nvalue = [47, 1, 0, 0]\"] ;\n",
      "9 -> 11 ;\n",
      "12 [label=\"Pollution Burden <= 16.894\\ngini = 0.364\\nsamples = 92\\nvalue = [22, 70, 0, 0]\"] ;\n",
      "9 -> 12 ;\n",
      "25 [label=\"Pop. Char. Score <= 3.726\\ngini = 0.375\\nsamples = 16\\nvalue = [12, 4, 0, 0]\"] ;\n",
      "12 -> 25 ;\n",
      "35 [label=\"gini = 0.0\\nsamples = 11\\nvalue = [11, 0, 0, 0]\"] ;\n",
      "25 -> 35 ;\n",
      "36 [label=\"gini = 0.32\\nsamples = 5\\nvalue = [1, 4, 0, 0]\"] ;\n",
      "25 -> 36 ;\n",
      "26 [label=\"Pop. Char. Score <= 2.483\\ngini = 0.229\\nsamples = 76\\nvalue = [10, 66, 0, 0]\"] ;\n",
      "12 -> 26 ;\n",
      "31 [label=\"Pollution Burden Score <= 2.719\\ngini = 0.476\\nsamples = 23\\nvalue = [9, 14, 0, 0]\"] ;\n",
      "26 -> 31 ;\n",
      "33 [label=\"gini = 0.198\\nsamples = 9\\nvalue = [8, 1, 0, 0]\"] ;\n",
      "31 -> 33 ;\n",
      "34 [label=\"gini = 0.133\\nsamples = 14\\nvalue = [1, 13, 0, 0]\"] ;\n",
      "31 -> 34 ;\n",
      "32 [label=\"gini = 0.037\\nsamples = 53\\nvalue = [1, 52, 0, 0]\"] ;\n",
      "26 -> 32 ;\n",
      "10 [label=\"Pop. Char. Score <= 1.7\\ngini = 0.139\\nsamples = 120\\nvalue = [9, 111, 0, 0]\"] ;\n",
      "4 -> 10 ;\n",
      "43 [label=\"Pollution Burden <= 32.16\\ngini = 0.408\\nsamples = 28\\nvalue = [8, 20, 0, 0]\"] ;\n",
      "10 -> 43 ;\n",
      "45 [label=\"gini = 0.198\\nsamples = 9\\nvalue = [8, 1, 0, 0]\"] ;\n",
      "43 -> 45 ;\n",
      "46 [label=\"gini = 0.0\\nsamples = 19\\nvalue = [0, 19, 0, 0]\"] ;\n",
      "43 -> 46 ;\n",
      "44 [label=\"gini = 0.022\\nsamples = 92\\nvalue = [1, 91, 0, 0]\"] ;\n",
      "10 -> 44 ;\n",
      "2 [label=\"Pollution Burden Score <= 7.151\\ngini = 0.5\\nsamples = 470\\nvalue = [0, 0, 237, 233]\"] ;\n",
      "0 -> 2 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\n",
      "5 [label=\"Pop. Char.  <= 88.269\\ngini = 0.363\\nsamples = 193\\nvalue = [0, 0, 147, 46]\"] ;\n",
      "2 -> 5 ;\n",
      "21 [label=\"Pop. Char. Score <= 8.221\\ngini = 0.262\\nsamples = 161\\nvalue = [0, 0, 136, 25]\"] ;\n",
      "5 -> 21 ;\n",
      "27 [label=\"gini = 0.027\\nsamples = 73\\nvalue = [0, 0, 72, 1]\"] ;\n",
      "21 -> 27 ;\n",
      "28 [label=\"Pollution Burden Score <= 6.706\\ngini = 0.397\\nsamples = 88\\nvalue = [0, 0, 64, 24]\"] ;\n",
      "21 -> 28 ;\n",
      "29 [label=\"Pollution Burden <= 52.203\\ngini = 0.163\\nsamples = 67\\nvalue = [0, 0, 61, 6]\"] ;\n",
      "28 -> 29 ;\n",
      "51 [label=\"gini = 0.0\\nsamples = 46\\nvalue = [0, 0, 46, 0]\"] ;\n",
      "29 -> 51 ;\n",
      "52 [label=\"Pop. Char.  <= 84.334\\ngini = 0.408\\nsamples = 21\\nvalue = [0, 0, 15, 6]\"] ;\n",
      "29 -> 52 ;\n",
      "53 [label=\"gini = 0.0\\nsamples = 15\\nvalue = [0, 0, 15, 0]\"] ;\n",
      "52 -> 53 ;\n",
      "54 [label=\"gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 0, 6]\"] ;\n",
      "52 -> 54 ;\n",
      "30 [label=\"gini = 0.245\\nsamples = 21\\nvalue = [0, 0, 3, 18]\"] ;\n",
      "28 -> 30 ;\n",
      "22 [label=\"Pollution Burden Score <= 6.15\\ngini = 0.451\\nsamples = 32\\nvalue = [0, 0, 11, 21]\"] ;\n",
      "5 -> 22 ;\n",
      "23 [label=\"gini = 0.0\\nsamples = 11\\nvalue = [0, 0, 11, 0]\"] ;\n",
      "22 -> 23 ;\n",
      "24 [label=\"gini = 0.0\\nsamples = 21\\nvalue = [0, 0, 0, 21]\"] ;\n",
      "22 -> 24 ;\n",
      "6 [label=\"Pop. Char.  <= 73.909\\ngini = 0.439\\nsamples = 277\\nvalue = [0, 0, 90, 187]\"] ;\n",
      "2 -> 6 ;\n",
      "7 [label=\"Pollution Burden Score <= 8.242\\ngini = 0.476\\nsamples = 133\\nvalue = [0, 0, 81, 52]\"] ;\n",
      "6 -> 7 ;\n",
      "13 [label=\"Pop. Char. Score <= 7.235\\ngini = 0.269\\nsamples = 75\\nvalue = [0, 0, 63, 12]\"] ;\n",
      "7 -> 13 ;\n",
      "37 [label=\"gini = 0.0\\nsamples = 37\\nvalue = [0, 0, 37, 0]\"] ;\n",
      "13 -> 37 ;\n",
      "38 [label=\"Pollution Burden <= 62.502\\ngini = 0.432\\nsamples = 38\\nvalue = [0, 0, 26, 12]\"] ;\n",
      "13 -> 38 ;\n",
      "39 [label=\"Total Population <= 6393.5\\ngini = 0.185\\nsamples = 29\\nvalue = [0, 0, 26, 3]\"] ;\n",
      "38 -> 39 ;\n",
      "41 [label=\"gini = 0.0\\nsamples = 25\\nvalue = [0, 0, 25, 0]\"] ;\n",
      "39 -> 41 ;\n",
      "42 [label=\"gini = 0.375\\nsamples = 4\\nvalue = [0, 0, 1, 3]\"] ;\n",
      "39 -> 42 ;\n",
      "40 [label=\"gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 0, 9]\"] ;\n",
      "38 -> 40 ;\n",
      "14 [label=\"Pop. Char.  <= 63.274\\ngini = 0.428\\nsamples = 58\\nvalue = [0, 0, 18, 40]\"] ;\n",
      "7 -> 14 ;\n",
      "15 [label=\"gini = 0.117\\nsamples = 16\\nvalue = [0, 0, 15, 1]\"] ;\n",
      "14 -> 15 ;\n",
      "16 [label=\"Pop. Char.  <= 65.566\\ngini = 0.133\\nsamples = 42\\nvalue = [0, 0, 3, 39]\"] ;\n",
      "14 -> 16 ;\n",
      "55 [label=\"gini = 0.49\\nsamples = 7\\nvalue = [0, 0, 3, 4]\"] ;\n",
      "16 -> 55 ;\n",
      "56 [label=\"gini = 0.0\\nsamples = 35\\nvalue = [0, 0, 0, 35]\"] ;\n",
      "16 -> 56 ;\n",
      "8 [label=\"Pollution Burden <= 60.158\\ngini = 0.117\\nsamples = 144\\nvalue = [0, 0, 9, 135]\"] ;\n",
      "6 -> 8 ;\n",
      "47 [label=\"Pop. Char.  <= 76.331\\ngini = 0.315\\nsamples = 46\\nvalue = [0, 0, 9, 37]\"] ;\n",
      "8 -> 47 ;\n",
      "49 [label=\"gini = 0.0\\nsamples = 8\\nvalue = [0, 0, 8, 0]\"] ;\n",
      "47 -> 49 ;\n",
      "50 [label=\"gini = 0.051\\nsamples = 38\\nvalue = [0, 0, 1, 37]\"] ;\n",
      "47 -> 50 ;\n",
      "48 [label=\"gini = 0.0\\nsamples = 98\\nvalue = [0, 0, 0, 98]\"] ;\n",
      "8 -> 48 ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(tree.export_graphviz(tuned_tree, feature_names=X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to more improvements we can make to decision tree models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Section 4: Ensemble methods<a name = 'improve'></a>\n",
    "\n",
    "In the previous section, we mainly were focusing on fitting one tree and tuning its hyperparameters. You may have noticed that, although the training scores were extremely high, the validation scores usually weren't as high. This is where ensemble methods come in, namely bagging, random forests, and boosting. We call them \"ensemble methods\" because we fit many trees and we somehow aggregate the models to avoid overfitting - in bagging, for example, we take an average of models. The benefits of using ensemble methods may not be immediately apparent with the training and validation data, but might become clearer when we evaluate all our models on the test data at the end of the assignment.\n",
    "\n",
    "----\n",
    "\n",
    "Let's start with bagging!\n",
    "\n",
    "Bagging takes in $B$ different bootstrapped training data sets and we train our tree on each $b$th training set to get $\\hat{f}^{*b}(x)$. Then, we average all of the predictions to get \n",
    "\n",
    "$$\\hat{f}_{bag}(x) = \\frac{1}{B} \\sum_{b=1}^{B}\\hat{f}^{*b}(x)$$\n",
    "\n",
    "In terms of classifying, bagging records the class from each bootstrapped sample and chooses the most commonly occurring majority class among the B predictions.\n",
    "\n",
    "Let's proceed by using `BaggingClassifier` from scikit-learn's ensemble module ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)). \n",
    "\n",
    "**Question 4.1** Use the training data `X_train` and fit the bagging classifier. Call your model `bag_tree`. Score the model on the validation data -- has the score improved on the training or validation data?  Use `n_estimators = 100`, `max_samples = 700`, `max_features = 25`.\n",
    "\n",
    "\n",
    "*Note:* We're not specifying a `random_state` to use with `BaggingClassifier()` here, but if you want your results to be reproducible you may want to set one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  1.0\n",
      "Validation Score:  0.919732441471572\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_tree = BaggingClassifier(random_state = 10, n_estimators = 100, max_samples = 700, max_features = 25)\n",
    "bag_tree.fit(X_train, y_train)\n",
    "\n",
    "bag_train_score = bag_tree.score(X_train, y_train)\n",
    "bag_val_score = bag_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', bag_train_score)\n",
    "print('Validation Score: ', bag_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2**  Note that as opposed to the \"standard\" tree we fit before, we're not cross-validating any parameters.  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3** What are some drawbacks of bagging compared to a single decision tree? Describe one way to compare the quality of a single decision tree model to a bagged model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Now, we'll move on to random forests.\n",
    "\n",
    "Random forests take a similar approach to bagging, in which we fit various decision trees on resampled data. But, when each tree is constructed, not every feature is considered as split candidates for each decision point; we only take a subset of the total predictors in the model.\n",
    "\n",
    "The idea behind a random forest is that adding randomization into the features that create the model and then averaging predictions across models will produce a model that is not as overfit to the training data, and is in turn more reliable for prediction.\n",
    "\n",
    "We'll use scikit-learn's `RandomForestClassifier()` to implement our model. The documentation can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "\n",
    "**Question 4.4** Create a default RandomForestClassifier and same as before, fit the training data and score the model. Call the model `rf_tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9955357142857143\n",
      "Validation Score:  0.8729096989966555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/app/venv/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_tree = RandomForestClassifier()\n",
    "rf_tree.fit(X_train, y_train)\n",
    "\n",
    "rf_train_score = rf_tree.score(X_train, y_train)\n",
    "rf_val_score = rf_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', rf_train_score)\n",
    "print('Validation Score: ', rf_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.5** Review the sklearn documentation on random forests to identify what hyperparameters might improve model performance.  In particular, what is `max_depth`, and what should you choose it to be? (You might want to consult with lecture notes and the textbook for guidance.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.6** Decide what other hyperparameters will affect model performance (things like tree depth, maximum number of observations per leaf, etc).  Choose values for those parameters and pass them in to a new random forest classifier and fit the model, then print out errors with training and validation data. Call your model `rf_newparams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  1.0\n",
      "Validation Score:  0.9264214046822743\n"
     ]
    }
   ],
   "source": [
    "#solution\n",
    "rf_newparams = RandomForestClassifier(max_features=\"auto\", max_leaf_nodes = None,\n",
    "                    min_samples_leaf=1, min_samples_split=2, n_estimators=100, \n",
    "                    random_state = 3)\n",
    "rf_newparams.fit(X_train, y_train)\n",
    "\n",
    "rf_train_score = rf_newparams.score(X_train, y_train)\n",
    "rf_val_score = rf_newparams.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', rf_train_score)\n",
    "print('Validation Score: ', rf_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to bagging, we cannot visualize a random forest; the reduction in variance comes at the price of interpretability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Lastly, we'll cover boosting, which is yet another approach to improve a decision tree model. The boosting approach grows a tree slowly. Each boosting algorithm has a slightly different approach, but the general idea is the same behind each one.\n",
    "\n",
    "First, we'll briefly cover AdaBoost (for ADAptive BOOSTing). The adaptive part of the algorithm comes from how it updates the data for each weak model in the sequence; it combines many relatively weak and inaccurate classifiers. So it shines when a regular classifier doesn't perform well with a given dataset.\n",
    "\n",
    "We can use `AdaBoostClassifier` from scikit-learn to try this out. Run the following cell to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.5100446428571429\n",
      "Validation Score:  0.4916387959866221\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_tree = AdaBoostClassifier()\n",
    "ada_tree.fit(X_train, y_train)\n",
    "\n",
    "ada_train_score = ada_tree.score(X_train, y_train)\n",
    "ada_val_score = ada_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', ada_train_score)\n",
    "print('Validation Score: ', ada_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops. It doesn't look too great. One thing with AdaBoost is that it doesn't handle noisy data or outliers well. In this case, our data is basically polarized -- we're taking values from the top and bottom 10% -- which means it might not work as well as we want it to.\n",
    "\n",
    "We can turn to gradient boosting, which is another boosting method. Gradient boosting involves three elements:\n",
    "1. A loss function to be optimized.\n",
    "2. A weak learner to make predictions.\n",
    "3. An additive model in which we add weak learners to minimize the loss function.\n",
    "\n",
    "We'll use scikit-learn's `GradientBoostingClassifier` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)) to see how it performs with our data.\n",
    "\n",
    "**Question 4.7** We'll do this for the last time! Fit the training data to the GradientBoostingClassifier and score the model. How much did it improve over the original model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  1.0\n",
      "Validation Score:  0.9331103678929766\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_tree = GradientBoostingClassifier()\n",
    "gb_tree.fit(X_train, y_train)\n",
    "\n",
    "gb_train_score = gb_tree.score(X_train, y_train)\n",
    "gb_val_score = gb_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', gb_train_score)\n",
    "print('Validation Score: ', gb_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.8** In the case of boosting, cross validation helps for hyperparameter tuning.  Figure out what parameters you'd like to search over, choose a range for them, and pass them into `RandomizedSearchCV` as we did in part 3.  Then save and print out the best parameters. (this will probably take a while to run, depending on how many parameters you choose!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/app/venv/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1, 'max_depth': 8, 'max_features': 13, 'min_samples_leaf': 7}\n",
      "CPU times: user 7min 20s, sys: 389 ms, total: 7min 20s\n",
      "Wall time: 7min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_dist = {'learning_rate': randint(1, 5),\n",
    "              #'max_leaf_nodes': randint(3, 100),\n",
    "              'max_features': randint(2, 25),\n",
    "              'max_depth': randint(1, 10),\n",
    "              'min_samples_leaf': randint(1, 30)}\n",
    "\n",
    "rnd_gb_search = RandomizedSearchCV(gb_tree, param_distributions=param_dist, \n",
    "                                cv=10, n_iter=50)\n",
    "\n",
    "rnd_gb_search.fit(X_train, y_train)\n",
    "\n",
    "print(rnd_gb_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.9** Once the search is complete, set the parameters and re-fit and score the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  1.0\n",
      "Validation Score:  0.9431438127090301\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "gb_tree.set_params(learning_rate=.1, max_depth=5, max_features=18, max_leaf_nodes=47, \n",
    "                   min_samples_leaf=9)\n",
    "gb_tree.fit(X_train, y_train)\n",
    "\n",
    "print('Train Score: ', gb_tree.score(X_train, y_train))\n",
    "print('Validation Score: ', gb_tree.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With boosting, we can also find the relative feature importance with this boosted model. This can help with the feature importance like before. \n",
    "\n",
    "**Question 4.10**  Get the feature importances and calculate the *relative* feature importance, which is each feature divided by the maximum feature importance multiplied by 100. Load the data into a table called `gb_feat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "feature_importance = gb_tree.feature_importances_\n",
    "#relative feature importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "gb_feat = pd.DataFrame({'feature':X_train.columns, 'importance':feature_importance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total Population</td>\n",
       "      <td>1.075208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ozone</td>\n",
       "      <td>0.092493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PM2.5</td>\n",
       "      <td>0.095292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diesel PM</td>\n",
       "      <td>0.294184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drinking Water</td>\n",
       "      <td>0.338599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pesticides</td>\n",
       "      <td>0.146532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tox. Release</td>\n",
       "      <td>0.074052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Traffic</td>\n",
       "      <td>0.146383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cleanup Sites</td>\n",
       "      <td>1.367732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Groundwater Threats</td>\n",
       "      <td>0.459001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Haz. Waste</td>\n",
       "      <td>1.250011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Imp. Water Bodies</td>\n",
       "      <td>0.093873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Solid Waste</td>\n",
       "      <td>1.252488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pollution Burden</td>\n",
       "      <td>66.867808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pollution Burden Score</td>\n",
       "      <td>54.180190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Asthma</td>\n",
       "      <td>2.833348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Low Birth Weight</td>\n",
       "      <td>0.610203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cardiovascular Disease</td>\n",
       "      <td>1.146340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Education</td>\n",
       "      <td>9.978624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Linguistic Isolation</td>\n",
       "      <td>0.738253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Poverty</td>\n",
       "      <td>0.466469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Unemployment</td>\n",
       "      <td>0.342645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Housing Burden</td>\n",
       "      <td>0.799842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pop. Char.</td>\n",
       "      <td>97.270527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pop. Char. Score</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  importance\n",
       "0         Total Population    1.075208\n",
       "1                    Ozone    0.092493\n",
       "2                    PM2.5    0.095292\n",
       "3                Diesel PM    0.294184\n",
       "4           Drinking Water    0.338599\n",
       "5               Pesticides    0.146532\n",
       "6             Tox. Release    0.074052\n",
       "7                  Traffic    0.146383\n",
       "8            Cleanup Sites    1.367732\n",
       "9      Groundwater Threats    0.459001\n",
       "10              Haz. Waste    1.250011\n",
       "11       Imp. Water Bodies    0.093873\n",
       "12             Solid Waste    1.252488\n",
       "13        Pollution Burden   66.867808\n",
       "14  Pollution Burden Score   54.180190\n",
       "15                  Asthma    2.833348\n",
       "16        Low Birth Weight    0.610203\n",
       "17  Cardiovascular Disease    1.146340\n",
       "18               Education    9.978624\n",
       "19    Linguistic Isolation    0.738253\n",
       "20                 Poverty    0.466469\n",
       "21            Unemployment    0.342645\n",
       "22          Housing Burden    0.799842\n",
       "23             Pop. Char.    97.270527\n",
       "24        Pop. Char. Score  100.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell to display gb_feat\n",
    "gb_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.11** Let's take a look at how these features compare with each other. Sort the values in the dataframe and create a bar chart that displays the feature importances in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "gb_feat = gb_feat.sort_values(by='importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(8, 7.5))\n",
    "plt.barh(width=gb_feat.importance, y=gb_feat.feature);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "We've gone through many methods of creating a decision tree and tuning and improving it, as well as various algorithms that use multiple trees to create a more reliable tree for prediction. Even though we've primarily have been testing our models with the training and validation set, we would still need to cross validate each of these models to see which one is the optimal one to choose given our data and how the model performs (this is even more important when a lot of the scores turned up around 92-93%). \n",
    "\n",
    "Before you finish up this homework, run the following cell to see which has the highest score with our test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  0.8896321070234113\n",
      "Test Score:  0.919732441471572\n",
      "Test Score:  0.9264214046822743\n",
      "Test Score:  0.8561872909698997\n",
      "Test Score:  0.9063545150501672\n",
      "Test Score:  0.4816053511705686\n",
      "Test Score:  0.9531772575250836\n"
     ]
    }
   ],
   "source": [
    "models = [first_tree, tuned_tree, bag_tree, rf_tree, rf_newparams, ada_tree, gb_tree]\n",
    "for i in models:\n",
    "    print('Test Score: ', i.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5: Project<a name = 'project'></a>\n",
    "\n",
    "**Question 5.1** Think of a way to apply classification methods to the data and problem area that you're exploring through your project. What would your response variable be? Is there any policy or real-world motivation for applying a classification  method in this way?\n",
    "\n",
    "*Note*: you don't have to use classification in your project, but it's useful to think through how you might. You don't have to predict a variable that's already qualitative - you can also think of how to bin quantitative data into different classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Submission\n",
    "\n",
    "Congrats, you're done with homework 9! \n",
    "\n",
    "In order to turn in this assignment, go to the toolbar and click **File** -> **Download as** -> **.html** and **.ipynb**. Submit the files through bCourses.\n",
    "\n",
    "----\n",
    "\n",
    "Notebook developed by: Jason Jiang\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
