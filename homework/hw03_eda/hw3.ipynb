{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\" # put your full name here\n",
    "COLLABORATORS = [] # list names of anyone you worked with on this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ERG-131] Homework 3: EDA Fire Incident Data\n",
    "<br>\n",
    "\n",
    "### Table of Contents\n",
    "[Introduction](#intro)<br>\n",
    "1 - [The data](#data)<br>\n",
    "2 - [Exploring data through tables and visuals](#tables_plots)<br>\n",
    "3 - [Summarizing data](#summarize)<br>\n",
    "\n",
    "### Introduction <a id='intro'></a>\n",
    "\n",
    "In this homework, you will investigate fire incident data from the three California Investor Owned Utilities (IOUs). The main goal for this assignment is to establish different ways to explore your data and its limitations, as well as ways to summarize and re-organize data.\n",
    "\n",
    "We will accomplish this by analyzing utility-reported data as well as weather data and utilizing exploratory data analysis (EDA).\n",
    "\n",
    "### Topics Covered \n",
    "\n",
    "* Work with different file types\n",
    "* Merge dataframes and perform operations to add new columns\n",
    "* View data through lens of structure, granularity, scope, temporality and faithfulness\n",
    "* Perform basic data cleaning operations\n",
    "\n",
    "**Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook.\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from IPython.display import display, Latex, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Section 1: The Data<a id='data'></a>\n",
    "\n",
    "In this notebook, you'll be working with data from the [California Public Utilities Commission](https://www.cpuc.ca.gov/fireincidentsdata/). The three California IOUs (PG&E, SCE, and SDGE) are required to report fire incidents to the CPUC, along with certain characteristics of the fire and the electrical system in the area.\n",
    "\n",
    "<br>**Question 1.1:** Look through the `data` folder and then load the .csv files into the homework so we can easily work with the data. These files were retrieved from the CPUC website, and small adjustments were made on Excel to make them easily retrievable in the notebook. The first example (PG&E) has been done for you.\n",
    "\n",
    "Take a look at the arguments that are passed to the `read_csv` function. First, we specify the file location. We also set  `index_col` to `False`.  This forces numbered indices.  As an alternative we could have passed a number to `index_col`; if we pass $n$ in, then pandas uses the $n+1^{\\text{st}}$ column of the csv as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pge = pd.read_csv('data/PGEfireincidents.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load Southern California Edison ('SCEfireincidents.csv') and San Diego Gas and Electric ('SDGEfireincidents.csv') data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sce = ... #YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sce.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdge = ... #YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2**: We'll also be working with weather data from the National Oceanic and Atmospheric Administration (NOAA). [Daily Summary Data](https://www.ncdc.noaa.gov/cdo-web/datasets#GHCND) was obtained for one land-based weather station per IOU service area from January 2014 to December 2016. Load the file noaa_dailysummary.csv below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to be merging fire incident data between each IOU and a land-based weather station in that IOU's service area. There are three weather stations in the dataframe `weather`, as shown in the output below. 'SAN DIEGO INTERNATIONAL AIRPORT, CA US' is in SDG&E's service area, 'SAN FRANCISCO DOWNTOWN, CA US' is in PG&E's service area, and 'RIVERSIDE MUNICIPAL AIRPORT, CA US' is in SCE's service area. <br>\n",
    "\n",
    "Since we're going to use the `merge()` function in the next part and we need the fields that we merge on to have the same name, we started by renaming the \"DATE\" column in `weather` to match the \"Fire Start Date\" column in the iou dataframes using the function `.rename()`, and then converted the data type of all the date columns to `datetime` in the cell below.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"NAME\"].unique() # look at weather station values\n",
    "weather.rename(columns = {\"DATE\":\"Fire Start Date\"}, inplace = True) # rename data column\n",
    "for df in [pge, sce, sdge, weather]: # change date data type to datetime\n",
    "    df[\"Fire Start Date\"] = pd.to_datetime(df[\"Fire Start Date\"], errors = \"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3a**: For this question, create three new dataframes - `weather_sdge`, `weather_pge`, and `weather_sce` - that correspond to just the weather data in that IOU's service area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_sdge = ... # YOUR CODE HERE\n",
    "weather_pge = ... # YOUR CODE HERE\n",
    "weather_sce = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_sdge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_pge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_sce.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3b**: Merge each utility's fire incident and weather data and save the merged dataframe with the same name as the utility's fire incident dataframe (i.e. we should have three dataframes, `sdge`, `pge`, and `sce`, that contain fire incident and weather data). The data should be merged on the date fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pge = ... # YOUR CODE HERE\n",
    "sce = ... # YOUR CODE HERE\n",
    "sdge = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sce.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before combining data from all three IOUs, we'll run the following `assert` statements to make sure that the column names are the same.\n",
    "\n",
    "*Note*: because the reporting is standardized for these IOUs, and because of some Excel cleaning that was done beforehand, the column names should match up. But if you're working with a dataset where column names need to be changed, you can use the [`rename` function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html) or a value assigment (eg. `sdge.columns = sce.columns` would set the columns of `sdge` to be the same as those in `sce`, as long as you were certain that the columns represented the same values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(pge.columns == sce.columns)\n",
    "assert all(sce.columns == sdge.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use [`concat()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html#pandas.concat) to combine all three dataframes into one, called `alliou`. Fill in the cell below to combine the three IOU dataframes. We want our new dataframe `alliou` to renumber the indices (otherwise we'd have three rows with row index = 0, three rows with row index = 1, etc.). Check the [`concat()` documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html#pandas.concat) and make sure that you've set the appropriate argument to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alliou = pd.concat(...) # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 36)\n",
    "alliou.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert alliou.shape[0] > 1000\n",
    "assert all(iou in alliou[\"Utility Name\"].unique() for iou in [\"PG&E\", \"SCE\", \"SDG&E\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4:** \n",
    "Analyze the `alliou` table and see what data types are within the table. \n",
    "<br>What is the:\n",
    "1. structure of the data?<br>\n",
    "2. granularity of the data?<br>\n",
    "3. scope of the data?<br>\n",
    "4. temporality of the data?<br>\n",
    "5. faithfulness of the data?<br>\n",
    "\n",
    "Some questions to ask yourself:\n",
    "* Structure - What was the format or file type of the imported data? Are there are any differences in data types between the individual IOU dataframes, the weather dataframe, and the combined dataframe?\n",
    "* Granularity - What does each row of data represent? Do any of the fields represent aggregated data (data that is reduced or summarized in some way)? What's the resolution in time (eg. hourly, monthly) of the data?\n",
    "* Scope - You can think of scope in different dimensions, but geographic scope and temporal scope is one place to start.\n",
    "* Temporality - What do the dates and times represent?\n",
    "* Faithfulness - Where do the data come from? Is there any reason to question it? \n",
    "\n",
    "Please make a couple observations for each category (structure, granularity, etc). The [NOAA's Daily Summary Documentation](https://www1.ncdc.noaa.gov/pub/data/cdo/documentation/GHCND_documentation.pdf) might be a helfpul resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5**: To get a basic estimate of weather conditions on the day of the fire incident, we took daily summaries from one weather station in the service area of each IOU. This approach isn't particularly granular - the IOU datasets provide more detail both in terms of geography and time than the weather data that we are using. Let's say you wanted to refine this approach to more effectively uncover the weather conditions in the location and at the time of the fire incident. In a few sentences, qualitatively describe an alternative approach. <br>\n",
    "You don't have to specify any code or functions, but you should reference which columns you would use (either in the IOU or weather datasets) and which datasets you would use - you can take a look at [available NOAA data here](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6:** What are the unique `Size` categories in the `alliou` table? Are there any redundancies in how the fire sizes are bucketed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Section 2: Exploring data through tables and visuals<a id='tables_plots'></a>\n",
    "\n",
    "In this section, we'll do some data cleaning with the objective of exploring the fire incident data.\n",
    "\n",
    "<br>**Question 2.1:** Create three dataframes, `alliou_2014`, `alliou_2015`, and `alliou_2016`, containing data from each year. You can use the [`.dt.year`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.year.html) method to extract the year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alliou_2014 = ... # YOUR CODE HERE\n",
    "alliou_2015 = ... # YOUR CODE HERE\n",
    "alliou_2016 = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alliou_2014.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alliou_2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alliou_2016.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2**: Use `pd.value_counts()` to get the number of reported fire incidents by utility and year. What do you notice about the relative number of reports by utility? What are some factors that could explain the differences in number of reports, particularly between PG&E and SCE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2014\n",
    "pd.value_counts(...) # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2015\n",
    "pd.value_counts(...) # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016\n",
    "pd.value_counts(...) # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3:** Create a column called `Size_clean` that contains cleaned values from the `Size` column of the `alliou` dataframe, renamed to address any redundancies. The resulting column should have 9 unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy column and rename so we retain the original column. The uncleaned column can be deleted later if you'd like - \n",
    "# but this way avoid any irreversible edits\n",
    "alliou[\"Size_clean\"] = alliou[\"Size\"]\n",
    "\n",
    "# YOUR CODE HERE TO CLEAN Size_clean COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alliou[\"Size_clean\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(alliou[\"Size_clean\"].unique()) == 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4:** Create a bar plot of how often each fire size category appears in the `alliou` dataframe. Use the function `pd.value_counts()` and the method `.plot` on the data frame. Which fire sizes come up the most frequently in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(...).plot.bar() # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5:** Use `plot()` to view the distribution of fire start dates in the `alliou` dataframe. Are there periods of time when fires occur more frequently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(...).plot() # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6**: Look at the `Was There an Outage` field. Perform any necessary data cleaning operations, then use `plot().bar()` to show how frequently the field was marked \"yes\" or \"no\" in the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(...).plot.bar() # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "----\n",
    "\n",
    "## Section 3. Summarizing data<a id='summarize'></a>\n",
    "\n",
    "One of the CPUC's goals when collecting this data is to identify operational and environmental trends related to fire incidents, with the objective of improving regulations and internal standards for utilities. In this section, you'll create a two new dataframes: one that summarizes fire incident data by equipment type, and another that summarizes weather data by month. In the process, you'll gain more experience with using `.groupby()` along with summarizing data that is non-numerical or doesn't lend itself as well to `.groupby()`. \n",
    "<br>\n",
    "\n",
    "**Question 3.1:** Define a new dataframe, `alliou_equipment`, that contains a single column with every unique value for \"Equipment Involved With Ignition\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alliou_equipment = pd.DataFrame()\n",
    "alliou_equipment[\"Equipment Involved With Ignition\"] = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alliou_equipment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2a:** The first set of values that we want to add to the dataframe is a count of the total number of fire incidents associated with each equipment type. Start by using `groupby().size()` to get a count of records for each equipment type and save it to variable `counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2b**: Now we want to put the values from `counts` into a new column in dataframe `alliou_equipment`. Do this below, making sure the right values from `counts` map to the correct equipment types. The resulting `alliou_equipment` dataframe should have two columns, one for equipment and one for the count of fire incidents.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alliou_equipment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3a** Next, we want to find out what percentage of fire incidents involving each equipment lead to outages. Add a column called \"% Outage\" to `alliou_equipment` that provides this value. There are lots of ways to approach finding the percentage of fire incidents that led to outages per equipment type, but some helpful functions might be `groupby()` and `np.divide()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "alliou_equipment[\"% Outage\"] = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alliou_equipment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3b**: You're working for the CPUC, and as you're exploring the fire incident data a colleague notices that almost 91% of fire incidents involving switches lead to outages. Your colleague concludes that the focus of the commission should be to work with utilities to inspect and revise switch maintenance and operation procedures. Do you agree with your colleague? Why or why not? Is there any additional data that you would want to collect before deciding where to focus maintenance review efforts? <br>\n",
    "*Note*: you don't have to reference or have a knowledge of electrical equipment to answer this - think more about what the data does or doesn't tell you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4** We'd also like to explore monthly weather trends. To start off, create a new column in `alliou` called \"Fire Start Month\" that includes the month of the fire incident (the `.dt.month` method is helfpul here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alliou[\"Fire Start Month\"] = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alliou.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert alliou.shape[1] == 33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5** Use `.groupby()` to create a dataframe, `alliou_monthly`, that shows *average* weather data values for each month and utility. To do so, you'll need to give `.groupby()` two arguments in the form of a list.<br>\n",
    "*Note*: You'll notice that the dataframe `alliou_monthly` will only provide grouped data for the weather-related variables, since none of the variables in the IOU dataset are stored as numbers (and so we can't calculate their mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alliou_month = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alliou_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6:** Define a function `temp_range()` that takes as input the month of the year (as a number) and the utility name (as a string) and returns the difference between the average maximum and average minimum temperature for that service area and month, rounded to one decimal place. Check out the [MultiIndex documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#advanced-indexing-with-hierarchical-index) for more information on how to use `.loc()` to access the values you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_range(month, utility):\n",
    "    \"\"\"\n",
    "    Calculate the difference between the average maximum temperature and average minimum temperature for a given utility's land-based temperature measurement in a certain month.\n",
    "    \n",
    "    Args:\n",
    "        month, an integer representing the month of the year\n",
    "        utility, a string representing the utility (acceptable values are \"PG&E\", \"SCE\", and \"SDG&E\")\n",
    "    \n",
    "    Returns:\n",
    "        The difference between average maximum and minium temperature, rounded to one decimal place (float)\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_range(11, \"SCE\"))\n",
    "print(temp_range(1, \"PG&E\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Submission\n",
    "\n",
    "Congrats, you're done with homework 3!\n",
    "\n",
    "Before you submit, click **Kernel** --> **Restart & Clear Output**. Then, click **Cell** --> **Run All**. Then, go to the toolbar and click **File** -> **Download as** -> **.html** and submit the file **as both an .html and .ipynb file through bCourses**.\n",
    "\n",
    "----\n",
    "\n",
    "## Bibliography\n",
    "\n",
    "- CPUC Fire Incident Data Collection: https://www.cpuc.ca.gov/fireincidentsdata/\n",
    "- NOAA Daily Summary Documentation: https://www1.ncdc.noaa.gov/pub/data/cdo/documentation/GHCND_documentation.pdf"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
