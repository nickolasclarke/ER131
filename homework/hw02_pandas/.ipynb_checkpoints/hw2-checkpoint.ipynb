{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\" # put your full name here\n",
    "COLLABORATORS = [] # list names of anyone you worked with on this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ERG-131] Homework 2: Pandas EPA Air Quality\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "[Introduction](#intro)<br>\n",
    "1 - [Downloading the Data](#data)<br>\n",
    "2 - [Preparing the Data](#prep)<br>\n",
    "3 - [Exploring Data with Pandas](#explore)<br>\n",
    "4 - [California Data](#cadata)<br>\n",
    "\n",
    "# Introduction <a id='intro'></a>\n",
    "\n",
    "In this homework, we will investigate air quality data retreived from the EPA. The main goal for this assignment is to understand how PM2.5 FRM/FEM Mass effects air quality. We will accomplish this by analyzing EPA data and utilizing pandas (a powerful Python data analysis toolkit). To give us a sense of how we think about each discovery we make and what next steps it leads to we will provide comments and insights along the way.\n",
    "\n",
    "### Topics Covered\n",
    "\n",
    "As we clean and explore these data, you will gain practice with:\n",
    "* Manipulating tables and parts of the table (column, index)\n",
    "* Identifying the type of data collected, missing values, anomalies, etc.\n",
    "* Computing numeric operations (mean, variance)\n",
    "* Merging and analyzing data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Section 1: Downloading the Data<a id='data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import math\n",
    "import zipfile\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the assignment, run the cell below to set up some imports that we will need for this assignment:\n",
    "\n",
    "In many of these assignments (and future adventures as a data scientist) we will use os, zipfile, pandas, numpy, matplotlib.pyplot, and seaborn.  \n",
    "\n",
    "**Question 1.1:** Import each of these libraries `as` their commonly used abbreviations (e.g., `pd`, `np`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this homework, we'll be working with air quality data from the EPA; we want to read the description of the data and download the data from the website.</div>\n",
    "\n",
    "A description of the data is [here](https://aqs.epa.gov/aqsweb/airdata/FileFormats.html#_hourly_data_files).\n",
    "\n",
    "We can then download the data. [Here is the site](https://aqs.epa.gov/aqsweb/airdata/download_files.html).\n",
    "\n",
    "To download the data, use a link like this:\n",
    "\n",
    "https://aqs.epa.gov/aqsweb/airdata/hourly_TYPE_YEAR.zip\n",
    "\n",
    "...where we can fill in \"TYPE\" with the measurement we want and \"YEAR\" with the year.\n",
    "\n",
    "**Measurement | (TYPE)**  \n",
    "Ozone | (44201)  \n",
    "SO2 | (42401)  \n",
    "CO | (42101)  \n",
    "NO2 | (42602)  \n",
    "PM2.5 FRM/FEM Mass | (88101)  \n",
    "PM2.5 non FRM/FEM Mass | (88502)  \n",
    "PM10 Mass | (81102)  \n",
    "PM2.5 Speciation | (SPEC)  \n",
    "PM10 Speciation | (PM10SPEC)\n",
    "\n",
    "\n",
    "We'll focus on PM2.5 Mass (88101) from 2018 in the problem set. Although it's possible to download the dataset exclusively through the notebook environment, the dataset is too large (over 4 million rows, 1.3GB in size!) to load and process in datahub given the memory constraint. Because of this, we'll be using a reduced version of this dataset which removes readings from certain states that we will not be working with.\n",
    "\n",
    "<br>\n",
    "Let's start by using Python to unzip the file and see how this data is laid out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_path = Path('data/reduced_PM25_2018.zip')\n",
    "zf = zipfile.ZipFile(air_quality_path, 'r')\n",
    "print([f.filename for f in zf.filelist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is only one CSV file within the zip file. From here, we want to then get a sense of the structure of the data within the CSV.\n",
    "\n",
    "**Question 1.2:** Load the CSV file in the zip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = ... # YOUR CODE HERE\n",
    "with zf.open(f_name) as f:\n",
    "    for i in range(2):\n",
    "        print(f.readline().rstrip().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3:** Answer the following boolean expressions using `True` or `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all the files CSV files?\n",
    "all_files_appear_to_be_csv = ... # YOUR ANSWER HERE\n",
    "\n",
    "# Do all the files have a header line?\n",
    "all_files_contain_headers = ... # YOUR ANSWER HERE\n",
    "\n",
    "# Do all the strings in the file have quotes around them?\n",
    "strings_appear_quoted = ... # YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can then organize this data and read it better by putting it in a table! We will go over this in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Section 2: Preparing the Data<a id='prep'></a>\n",
    "\n",
    "We can see that the file contains a pretty descriptive header, and in fact these are explained in detail in the documentation at the url listed at the top of this notebook. Let's extract it. We are going to pretend there are multiple files in the zip file, and keep using `zf` to read the file and extract the information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with zf.open(f_name) as fh:\n",
    "    PM25_2018 = pd.read_csv(fh, low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM25_2018.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1:** Look through the table and see what data types are within the table. For this question, identify at least one issue relating to bad or missing data in the dataset, and outline (in one sentence) how this data-related issue could impact an analyst's ability to draw conclusions from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers can vary, but one answer is: the air quality uncertainty field (\"Uncertainty\") contains a lot of NaNs, which would make it difficult to compare air quality at different times or in different locations with any certainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2:** Find the dimensions of the table to figure out how much data we are working with.<br>\n",
    "*Hint*: the method `.shape` is helpful here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3:** With this information, we can answer the questions below.\n",
    "\n",
    "1. How many records are there?\n",
    "2. How many fields are reported?\n",
    "3. What does each row represent?\n",
    "4. After reading up on the data formats [here](https://aqs.epa.gov/aqsweb/airdata/FileFormats.html#_hourly_data_files), what does MDL stand for and what is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell for scratch work\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4:** How many records in the PM25_2018 dataframe have a smaller sample measurement than they do an MDL value? Are you more or less confident in those values than you are in the sample measurement values in the rest of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell for scratch work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5:** Create an array of all the unique state names in `PM25_2018`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6:** We can see that there are a lot of columns that are unneeded for this data analysis. Let's make a new dataframe with the information we need. Use pd.DataFrame to create a new table with 6 columns:\n",
    "1. `Date`: The column of dates corresponding to the `Date Local` column.\n",
    "1. `Time`: The time of day that sampling began on a 24-hour clock corresponding to the `Time Local` column.\n",
    "1. `Measurement`: The measured value in the standard units of measure for the parameter corresponding to the `Sample Measurement` column.\n",
    "1. `Units`: The unit of measure for the parameter corresponding to the `Units of Measure` column.\n",
    "1. `State`: The name of the state where the monitoring site is located.\n",
    "1. `County`: The name of the county where the monitoring site is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_table = ... \n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "----\n",
    "\n",
    "## Section 3: Exploring Data with Pandas<a id='explore'></a>\n",
    "\n",
    "According to researchers at the International Journal of Environmental Research and Public Health, PM2.5 is observed with higher concentrations in cold seasons and lower concentrations in warm seasons [(Link to paper)](https://www.ncbi.nlm.nih.gov/pubmed/26426035).\n",
    "\n",
    "In this section we will analyze our data and see whether this claim proves true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1:** Using the table from Question 2.6, create a new table containing just data from New York in Queens County. There should be 8481 rows in this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queens = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2:** Within the `queens` dataframe, find any rows where \"Measurement\" is lower than \"MDL\" and replace the value in \"Measurement\" in those rows with `np.nan` (the `.loc` method is helpful here!).  \n",
    "\n",
    "*Hint / Warning*: You may get a \"SettingWithCopyWarning\".  It's ok to ignore.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3:** Below, output all the measurements in `queens` taken at noon in January and all the measurements taken at noon in June. What do you notice?  You might try using the `.decribe` method to explore your June and January outputs separately.<br>\n",
    "*Note*: There are a lot of ways to extract the month from the date in Pandas, and we'll explore some of them in the next homework. For now, one approach (you're free to use another) is to use the [`.str.contains`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.contains.html) method. For instance, if a Date cell contains the substring \"2018-02\", that means the date is in February 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noon in january\n",
    "queens_jan = ... # YOUR CODE HERE\n",
    "queens_jan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noon in june\n",
    "queens_jun = ... # YOUR CODE HERE\n",
    "queens_jun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3:** We can also visualize this data and see how the PM2.5 concentrations fluctuate throughout the year. Run the code  below to plot all of the measurement data throughout the year.\n",
    "\n",
    "In order to better plot the x-axis, we have to convert the \"Date\" column in `queens` to `datetime` format. Otherwise the dates are read as strings, and while they will be plotted correctly, Python will not be able to label them correctly. \n",
    "\n",
    "Are there any noticeable trends in this plot? Are there any aspects of the plot that make it difficult for you to determine trends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.to_datetime(queens[\"Date\"]), queens[\"Measurement\"])\n",
    "\n",
    "plt.title(\"PM2.5 Concentrations in Queens, 2018\")\n",
    "plt.ylabel(\"PM2.5 Micrograms/cubic meter (LC)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4:** Let's try plotting values only in the months of January and February, and then only in the months of July and August. Create the dataframe `queens_winter` containing January and February values and `queens_summer` containing June and July values, and then run the corresponding cells. What do you notice about the two plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queens_winter = ... # YOUR CODE HERE\n",
    "\n",
    "plt.plot(pd.to_datetime(queens_winter[\"Date\"]), queens_winter[\"Measurement\"], 'ro', markersize=1)\n",
    "\n",
    "plt.title(\"PM2.5 Concentrations in Queens, November and December 2018\")\n",
    "plt.ylabel(\"PM2.5 Micrograms/cubic meter (LC)\")\n",
    "plt.xticks(rotation = 30)\n",
    "plt.ylim((0,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queens_summer = ... # YOUR CODE HERE\n",
    "\n",
    "plt.plot(pd.to_datetime(queens_summer[\"Date\"]), queens_summer[\"Measurement\"], 'ro', markersize = 1)\n",
    "\n",
    "plt.title(\"PM2.5 Concentrations in Queens, June and July 2018\")\n",
    "plt.ylabel(\"PM2.5 Micrograms/cubic meter (LC)\")\n",
    "plt.xticks(rotation = 30)\n",
    "plt.ylim((0,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4:** Do the data support the observation that PM2.5 concentrations are on average higher in colder months than warmer months? Why or why not? What are some of the limitations of either our data or the methods we've used to explore it so far in allowing us to observe seasonal trends?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5:** In Susan Athey's essay \"Beyond Prediction\", Athey defines the distinction between prediction problems and causal inference problems. Thinking about this air quality dataset, can you come up with one question that poses a prediction problem (also referred to a resource allocation problem in the essay) and another that poses a causal inference problem? The two questions you come up with should be air quality related, but you don't have to limit yourself to this dataset (eg. it's totally fair to come up with a question that would also incorporate, for example, census or demographic data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Section 4: California Data<a id='cadata'></a>\n",
    "\n",
    "Let's explore data that hits a little closer to home. In this section, we will look at air quality trends in California - more specifically Butte County. California is known for its wildfires and last year 5 California cities made it to the [top 10 worst cities for air quality in the United States and Canada](https://www.theguardian.com/cities/datablog/2017/feb/13/most-polluted-cities-world-listed-region). We will use data analysis to see how the fires have impacted PM2.5 cocentrations.\n",
    "\n",
    "<br>**Question 4.1:** Create a dataframe called `PM25_2018_CA` that is a subset of `state_table` and just has PM2.5 2018 California data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM25_2018_CA = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM25_2018_CA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Question 4.3:** Find the mean PM2.5 concentrations in each county. \n",
    "\n",
    "*hint: `groupby` is a helpful operation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Camp Fire, which started in November 2018,  that started on October 8 was described as the [‘deadliest, most destructive wildfire in California history’](https://www.washingtonpost.com/nation/2018/11/25/camp-fire-deadliest-wildfire-californias-history-has-been-contained/?noredirect=on).\n",
    "\n",
    "UC Berkeley students could smell and see the effects of the fires in Butte County. November 9, 2018 was one of the peak days that the fires were burning and we will analyze its effects on PM2.5 concentrations on this day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4:** Using `PM25_2018_CA`, create a table containing just information from Napa County on November 9, 2018 (although the fires occurred in Butte County, you'll notice from the list of unique counties that we don't have measurements for Butte - so we'll look at values in a nearby county)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "napa_nov9 = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "napa_nov9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.5:** Using `PM25_2018_CA`, create a table containing just information from Napa County on November 1, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "napa_nov1 = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "napa_nov1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.6:** Merge `napa_nov9` and `napa_nov1` on `Time` to compare their PM2.5 concentrations side by side.\n",
    "\n",
    "*Note:* If  two dataframes have the same column names when pandas executes a merge, it will append a '_x' to the first data frame column names and a '_y' to the second data frame column names.  The rename operation is meant to clarify things.  Be sure that it's renaming correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "napa_merge = ... # YOUR CODE HERE\n",
    "napa_merge.rename(columns={'Measurement_x':'Nov9 PM2.5', 'Measurement_y':'Nov1 PM2.5'}, inplace = True)\n",
    "napa_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.7:** Calcuate the mean PM2.5 measurements of both days. How do the PM2.5 concentrations will compare on these two dates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Submission\n",
    "\n",
    "Congrats, you're done with homework 2!\n",
    "\n",
    "Before you submit, click **Kernel** --> **Restart & Clear Output**. Then, click **Cell** --> **Run All**. Then, go to the toolbar and click **File** -> **Download as** -> **.html** and submit the file through bCourses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "\n",
    "## Bibliography\n",
    "\n",
    "- Yao, Ling, et al. - PM2.5 observations during the day vs at night. https://www.ncbi.nlm.nih.gov/pubmed/26426035\n",
    "- Guardian News and Media - Air quality rankings in cities. https://www.theguardian.com/cities/datablog/2017/feb/13/most-polluted-cities-world-listed-region\n",
    "- Washington Post - Camp Fire. https://www.washingtonpost.com/nation/2018/11/25/camp-fire-deadliest-wildfire-californias-history-has-been-contained/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: Melissa Ly\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
