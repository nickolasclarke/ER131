### Lecture 20 Reading

For Lecture 20 we'll discuss 
1. Support Vector Machines.  Read ISLR 9.1-9.3.
1. the New York Times Upshot aritcle, [Who's to Blame When Algorithms Discriminate](https://www.nytimes.com/2019/08/20/upshot/housing-discrimination-algorithms-hud.html). 
	a. What is the term used in this article to describe the condition that must be met to trigger federal protection in discrimination cases?  How does it relate to overt intent to discriminate?
		i. "disparate impact"
		ii. Federal protection typically triggers under conditions of disparate impact, even if no evidence of overt discriminatory actions.  
	b. What's the summary of the old Obama-era standard for who bears the burden of proof in discrimination cases?  What about the Trump administration's new rule?
		i. Obama: Defendants have to explain origins of disparate impact
		ii. Trump: Plaintiffs have to prove that an alternative policy would have averted disparate impact.  
	c. How do statistical learning models get mixed up in these rules?
		i. Under the new rules, plaintiffs would need to show that different algorithms could acheive the same goal without disparate impact.  That's very hard to do.
	d. Why is this conversation relevant to environmental justice?  
		i. One of the origins of environmental racism is housing segregation.  To the extent algorithms force people to live in specific areas, they can reinforce these problems.  